diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/database/clickhouse/history.sql glaber/database/clickhouse/history.sql
--- zabbix-4.0.1/database/clickhouse/history.sql	1970-01-01 05:00:00.000000000 +0500
+++ glaber/database/clickhouse/history.sql	2019-05-31 11:29:11.268895094 +0500
@@ -0,0 +1,16 @@
+
+CREATE TABLE zabbix.history_test ( day Date,  
+                                itemid UInt64,  
+                                clock DateTime,  
+                                ns UInt32,  
+                                value String,
+                                hostname String,
+                                itemname String) ENGINE = MergeTree(day, (itemid, clock, hostname, itemname), 8192);
+
+CREATE TABLE zabbix.history_test_buffer (day Date,  
+                                itemid UInt64,  
+                                clock DateTime,  
+                                ns UInt32,  
+                                value String,
+                                hostname String,
+                                itemname String) ENGINE = Buffer(zabbix, history_test, 16, 30, 100, 50000, 1000000, 1000000, 10000000) ;
\ В конце файла нет новой строки
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/app/views/monitoring.widget.problems.view.php glaber/frontends/php/app/views/monitoring.widget.problems.view.php
--- zabbix-4.0.1/frontends/php/app/views/monitoring.widget.problems.view.php	2018-10-29 22:36:01.000000000 +0500
+++ glaber/frontends/php/app/views/monitoring.widget.problems.view.php	2019-05-28 11:38:33.187894312 +0500
@@ -50,7 +50,7 @@
 	->setHeader(array_merge($header, [
 		$show_recovery_data ? _('Recovery time') : null,
 		$show_recovery_data ? _('Status') : null,
-		_('Info'),
+//		_('Info'),
 		($data['sortfield'] === 'host') ? [_('Host'), $sort_div] : _('Host'),
 		[
 			($data['sortfield'] === 'name') ? [_('Problem'), $sort_div] : _('Problem'),
@@ -148,6 +148,18 @@
 		$info_icons[] = makeSuppressedProblemIcon($problem['suppression_data']);
 	}
 
+
+//	$description = (new CCol([$problem['name']
+//		
+//		(new CLinkAction($problem['name']))
+//			->setHint(
+//				make_popup_eventlist($trigger, $eventid, $backurl, $data['fullscreen'], $show_timeline, $sortorder),
+//				'',
+//				true
+//			)
+// 	]));
+
+
 	$description = (new CCol([
 		(new CLinkAction($problem['name']))
 			->setHint(
@@ -212,7 +224,7 @@
 	$table->addRow(array_merge($row, [
 		$show_recovery_data ? $cell_r_clock : null,
 		$show_recovery_data ? $cell_status : null,
-		makeInformationList($info_icons),
+//		makeInformationList($info_icons),
 		$triggers_hosts[$trigger['triggerid']],
 		$description,
 		(new CCol(zbx_date2age($problem['clock'], ($problem['r_eventid'] != 0) ? $problem['r_clock'] : 0)))
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/classes/api/managers/CHistoryManager.php glaber/frontends/php/include/classes/api/managers/CHistoryManager.php
--- zabbix-4.0.1/frontends/php/include/classes/api/managers/CHistoryManager.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/classes/api/managers/CHistoryManager.php	2019-05-28 11:38:33.203894656 +0500
@@ -34,10 +34,15 @@
 	 * @return array    an array with items IDs as keys and arrays of history objects as values
 	 */
 	public function getLastValues(array $items, $limit = 1, $period = null) {
+
 		$results = [];
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getLastValuesFromClickHouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE], $limit,
+					$period
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getLastValuesFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC], $limit,
 					$period
 			);
@@ -55,6 +60,163 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
+	/**
+	 * Clickhouse implementation of getLastValues.
+	 *
+	 */
+
+
+private function getLastValuesFromClickhouse($items, $limit, $period) {
+
+	global $HISTORY, $ClickHouseDisableNanoseconds;
+	$results = [];
+	$itemslist='';
+
+	
+	foreach ($items as $item) {
+	    if (strlen($itemslist)>0) {
+	        $itemslist.=','.$item['itemid'];
+    	    } else {
+	        $itemslist.=$item['itemid'];
+		}
+	} 
+
+
+	$query_text='
+		SELECT 
+		    itemid, 
+		    max(toInt32(clock)) AS clk,'. ($ClickHouseDisableNanoseconds == 1 ? '0 AS ns_,' : 'argMax(ns, toInt32(clock)) AS ns_,')
+		    .'argMax(value, toInt32(clock)) AS val, 
+		    argMax(value_dbl, toInt32(clock)) AS val_dbl, 
+		    argMax(value_str, toInt32(clock)) AS val_str' .
+	' FROM '.$HISTORY['tablename'].' h'.
+	' WHERE h.itemid in ( '.$itemslist.')'.
+	($period ? ' AND h.clock>'.(time() - $period) : '').
+	' GROUP BY itemid';
+
+        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+	foreach ($values as $res) 
+	{
+		$itemid=$res['itemid'];
+
+		//i know this is shit code, but it works much better then 
+		//checking for item type for some reason (see it celow)
+		$res['value']=floatval($res['value_dbl'])+intval($res['value']);		
+		if (strlen($res['value_str']>0)) $res['value']=$res['value_str'];
+
+		if (empty($results[$itemid])) 
+		    {
+			$results[$itemid]=[$res];
+		    }
+	}
+
+//	foreach ($items as $item) {
+//	    if ( !empty($results[$item['itemid']])) {
+//	    	if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT && !empty($results[$item['itemid']]['value_dbl'])) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_dbl'];
+//	        }
+//		if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR) {
+//		    $results[$item['itemid']]['value']=$results[$item['itemid']]['value_str'];
+//		}
+//	    }
+//	    
+//	}
+
+	return $results;
+
+//	foreach ($items as $item) {
+//	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+//    		if (strlen($float_itemslist)>0) {
+//		        $float_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $float_itemslist.=$item['itemid'];
+//		}
+//	    } else if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+//		if (strlen($uint_itemslist)>0) {
+//		        $uint_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $uint_itemslist.=$item['itemid'];
+//		}
+//	    } else {
+//		if (strlen($str_itemslist)>0) {
+//		        $str_itemslist.=','.$item['itemid'];
+//    		} else {
+//		    $str_itemslist.=$item['itemid'];
+//		}
+//	    }
+//	}
+
+//	var_dump($itemslist);
+	
+//	$query_text='SELECT itemid, toInt32(clock) as clk,ns,value,value_dbl,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$uint_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+//
+//	$query_text.=' UNION ALL SELECT itemid, toInt32(clock) as clk,ns,value_str as value'.
+//	' FROM '.$HISTORY['tablename'].' h'.
+//	' WHERE h.itemid in ( '.$str_itemslist.')'.
+//	($period ? ' AND h.clock>'.(time() - $period) : '').
+//	' ORDER BY clk DESC';
+
+//	var_dump($query_text);
+    
+//        $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value','value_dbl','value_str'));
+
+//var_dump($values);
+
+/*
+	foreach ($items as $item) {
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_FLOAT) {
+		$query_text=	'SELECT itemid, toInt32(clock),ns,value_dbl'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid'].
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_UINT64) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($item['value_type'] ==  ITEM_VALUE_TYPE_STR || $item['value_type'] ==  ITEM_VALUE_TYPE_TEXT ) {
+		$query_text=	'SELECT itemid, toInt32(clock) as clock,ns,value_str'.
+		    ' FROM '.$HISTORY['tablename'].' h'.
+		    ' WHERE h.itemid= '.$item['itemid']. 
+		    ($period ? ' AND h.clock>'.(time() - $period) : '').
+		    ' ORDER BY h.clock DESC';
+	    }
+
+	    if ($limit > 0) $query_text.=" LIMIT $limit";
+	    
+	    $values = CClickHouseHelper::query($query_text,1,array('itemid','clock','ns','value'));
+
+//	    var_dump($values);
+	    if ($values) {
+		$results[$item['itemid']] = $values;
+	    } else {
+//			    error("Got empty array, ommiting the result");
+	    }
+	}
+
+	return $results;
+*/
+    }
+
 	private function getLastValuesFromElasticsearch($items, $limit, $period) {
 		$terms = [];
 		$results = [];
@@ -137,6 +299,7 @@
 	 *
 	 * @see CHistoryManager::getLastValues
 	 */
+
 	private function getLastValuesFromSql($items, $limit, $period) {
 		$results = [];
 
@@ -171,6 +334,7 @@
 	 * @return array    history value aggregation for graphs
 	 */
 	public function getGraphAggregation(array $items, $time_from, $time_to, $width = null) {
+//		error("Hello wold");
 		if ($width !== null) {
 			$size = $time_to - $time_from;
 			$delta = $size - $time_from % $size;
@@ -183,7 +347,13 @@
 		$grouped_items = self::getItemsGroupedByStorage($items);
 
 		$results = [];
-		if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
+
+
+		if (array_key_exists(ZBX_HISTORY_SOURCE_CLICKHOUSE, $grouped_items)) {
+			$results += $this->getGraphAggregationFromClickhouse($grouped_items[ZBX_HISTORY_SOURCE_CLICKHOUSE],
+					$time_from, $time_to, $width, $size, $delta
+			);
+		} else if (array_key_exists(ZBX_HISTORY_SOURCE_ELASTIC, $grouped_items)) {
 			$results += $this->getGraphAggregationFromElasticsearch($grouped_items[ZBX_HISTORY_SOURCE_ELASTIC],
 					$time_from, $time_to, $width, $size, $delta
 			);
@@ -203,6 +373,62 @@
 	 *
 	 * @see CHistoryManager::getGraphAggregation
 	 */
+	private function getGraphAggregationFromClickhouse(array $items, $time_from, $time_to, $width, $size, $delta) {
+
+		global $HISTORY;
+		$group_by = 'itemid';
+		$sql_select_extra = '';
+
+		if ($width !== null && $size !== null && $delta !== null) {
+			// Required for 'group by' support of Oracle.
+			$calc_field = 'round('.$width.'*'.'modulo(toUInt32(clock)'.'+'.$delta.",$size)".'/('.$size.'),0)';
+
+			$sql_select_extra = ','.$calc_field.' AS i';
+			$group_by .= ','.$calc_field;
+		}
+
+		$results = [];
+
+		foreach ($items as $item) {
+			if ($item['value_type'] == ITEM_VALUE_TYPE_UINT64) {
+				$sql_select = 'COUNT(*) AS count,AVG(value) AS avg,MIN(value) AS min,MAX(value) AS max';
+			} else
+			{
+				$sql_select = 'COUNT(*) AS count,AVG(value_dbl) AS avg,MIN(value_dbl) AS min,MAX(value_dbl) AS max';
+			}
+			$daystart=date('Y-m-d',$time_from);
+			$dayend=date('Y-m-d',$time_to);
+			
+			$query_text = 
+				'SELECT itemid,'.$sql_select.$sql_select_extra.',MAX(toUInt32(clock)) AS clock1'.
+				' FROM '. $HISTORY['tablename'] .
+				' WHERE itemid='.$item['itemid'].
+					' AND day >= \''.$daystart. '\''.
+					' AND day <= \''. $dayend. '\''.	 
+					' AND toUInt32(clock)>='.$time_from.
+					' AND toUInt32(clock)<='.$time_to.
+				' GROUP BY '.$group_by ;
+
+//			file_put_contents('/var/log/nginx/chartlog.log', "Will do query '$new_query_text' \n",FILE_APPEND);
+
+
+			$values = CClickHouseHelper::query($query_text,1,array('itemid','count','avg','min','max','i','clock'));
+
+			$results[$item['itemid']]['source'] = 'history';
+			$results[$item['itemid']]['data'] = $values;
+		}
+
+//	    ob_start();
+//	    var_dump($results);
+//	    $dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//	    file_put_contents('/var/log/nginx/chartlog.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+		return $results;
+
+	}
+
 	private function getGraphAggregationFromElasticsearch(array $items, $time_from, $time_to, $width, $size, $delta) {
 		$terms = [];
 
@@ -423,6 +649,8 @@
 	 */
 	public function getAggregatedValue(array $item, $aggregation, $time_from) {
 		switch (self::getDataSourceType($item['value_type'])) {
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getAggregatedValueFromClickhouse($item, $aggregation, $time_from);
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getAggregatedValueFromElasticsearch($item, $aggregation, $time_from);
 
@@ -431,6 +659,24 @@
 		}
 	}
 
+	private function getAggregatedValueFromClickhouse(array $item, $aggregation, $time_from) {
+
+		global $HISTORY;
+		$query_text =
+			'SELECT '.$aggregation.'(value) AS value'.
+			' FROM '. $HISTORY['tablename'].
+			' WHERE clock>toDateTime('.$time_from.')'.
+			' AND itemid='.$item['itemid'].
+			' HAVING COUNT(*)>0';
+		
+
+		$value = CClickHouseHelper::query($query_text,0,array());
+
+		return $value;
+
+	}
+
+
 	/**
 	 * Elasticsearch specific implementation of getAggregatedValue.
 	 *
@@ -623,8 +869,12 @@
 			global $HISTORY;
 
 			if (is_array($HISTORY) && array_key_exists('types', $HISTORY) && is_array($HISTORY['types'])) {
-				$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
-						? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
+					if ($HISTORY['storagetype']=='clickhouse') 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_CLICKHOUSE : ZBX_HISTORY_SOURCE_SQL;
+					else 
+							$cache[$value_type] = in_array(self::getTypeNameByTypeId($value_type), $HISTORY['types'])
+								? ZBX_HISTORY_SOURCE_ELASTIC : ZBX_HISTORY_SOURCE_SQL;
 			}
 			else {
 				// SQL is a fallback data source.
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/classes/api/services/CHistory.php glaber/frontends/php/include/classes/api/services/CHistory.php
--- zabbix-4.0.1/frontends/php/include/classes/api/services/CHistory.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/classes/api/services/CHistory.php	2019-05-28 11:38:33.203894656 +0500
@@ -112,7 +112,10 @@
 		switch (CHistoryManager::getDataSourceType($options['history'])) {
 			case ZBX_HISTORY_SOURCE_ELASTIC:
 				return $this->getFromElasticsearch($options);
-
+				break;
+			case ZBX_HISTORY_SOURCE_CLICKHOUSE:
+				return $this->getFromClickHouse($options);
+				break;
 			default:
 				return $this->getFromSql($options);
 		}
@@ -239,6 +242,129 @@
 	}
 
 	/**
+	 * Clickhouse specific implementation of get.
+	 *
+	 * @see CHistory::get
+	 */
+	private function getFromClickHouse($options) {
+i		global $HISTORY, $ClickHouseDisableNanoseconds;
+		$result = [];
+		$sql_parts = [
+			'select'	=> ['history' => 'h.itemid'],
+			'from'		=> [],
+			'where'		=> [],
+			'group'		=> [],
+			'order'		=> [],
+			'limit'		=> null
+		];
+
+
+		$value_col='value';
+
+		if ($options['history']==ITEM_VALUE_TYPE_FLOAT) {
+		    $value_col='value_dbl';
+		}
+
+		if ($options['history']==ITEM_VALUE_TYPE_STR) {
+		    $value_col='value_str';
+		}
+
+
+		$table_name = $HISTORY['tablename'];
+
+		$sql_parts['from']['history'] = $table_name.' h';
+
+		// itemids
+		if ($options['itemids'] !== null) {
+			$sql_parts['where']['itemid'] = "h.itemid =". $options['itemids'][0];
+		}
+
+		// time_from
+		if ($options['time_from'] !== null) {
+			$sql_parts['where']['clock_from'] = 'h.clock>='.zbx_dbstr($options['time_from']);
+		}
+
+		// time_till
+		if ($options['time_till'] !== null) {
+			$sql_parts['where']['clock_till'] = 'h.clock<='.zbx_dbstr($options['time_till']);
+		}
+
+		// filter
+		if (is_array($options['filter'])) {
+			$this->dbFilter($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// search
+		if (is_array($options['search'])) {
+			zbx_db_search($sql_parts['from']['history'], $options, $sql_parts);
+		}
+
+		// output
+		if ($options['output'] == API_OUTPUT_EXTEND) {
+			unset($sql_parts['select']['clock']);
+			$sql_parts['select']['history'] = 'h.*';
+		}
+
+		// countOutput
+		if ($options['countOutput']) {
+			$options['sortfield'] = '';
+			$sql_parts['select'] = ['count(DISTINCT h.hostid) as rowscount'];
+
+			// groupCount
+			if ($options['groupCount']) {
+				foreach ($sql_parts['group'] as $key => $fields) {
+					$sql_parts['select'][$key] = $fields;
+				}
+			}
+		}
+
+		// sorting
+		$sql_parts = $this->applyQuerySortOptions($table_name, $this->tableAlias(), $options, $sql_parts);
+
+		// limit
+		if (zbx_ctype_digit($options['limit']) && $options['limit']) {
+			$sql_parts['limit'] = $options['limit'];
+		}
+
+		$sql_parts['select'] = array_unique($sql_parts['select']);
+		$sql_parts['from'] = array_unique($sql_parts['from']);
+		$sql_parts['where'] = array_unique($sql_parts['where']);
+		$sql_parts['order'] = array_unique($sql_parts['order']);
+
+		$sql_select = '';
+		$sql_from = '';
+		$sql_order = '';
+
+		if ($sql_parts['select']) {
+			$sql_select .= implode(',', $sql_parts['select']);
+		}
+
+		if ($sql_parts['from']) {
+			$sql_from .= implode(',', $sql_parts['from']);
+		}
+
+		$sql_where = $sql_parts['where'] ? ' WHERE '.implode(' AND ', $sql_parts['where']) : '';
+
+		if ($sql_parts['order']) {
+			$sql_order .= ' ORDER BY '.implode(',', $sql_parts['order']);
+		}
+
+		$sql_limit = $sql_parts['limit'];
+		$sql = "SELECT itemid, toInt32(clock),". ($ClickHouseDisableNanoseconds == 1 ? "0 AS ns," : "ns",) ."$value_col".
+				' FROM '.$sql_from.
+				$sql_where.
+				$sql_order;
+
+//		var_dump($sql);
+		$values = CClickHouseHelper::query($sql,1,array('itemid','clock','ns', 'value'));
+
+
+//		error("Will exec sql $sql");
+
+		return $values;
+	}
+
+	/**
 	 * Elasticsearch specific implementation of get.
 	 *
 	 * @see CHistory::get
@@ -315,4 +441,5 @@
 
 		return null;
 	}
+
 }
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/classes/helpers/CClickHouseHelper.php glaber/frontends/php/include/classes/helpers/CClickHouseHelper.php
--- zabbix-4.0.1/frontends/php/include/classes/helpers/CClickHouseHelper.php	1970-01-01 05:00:00.000000000 +0500
+++ glaber/frontends/php/include/classes/helpers/CClickHouseHelper.php	2019-05-28 11:38:33.211894827 +0500
@@ -0,0 +1,99 @@
+<?php
+
+/*
+ * A helper class for working with ClickHouse database
+ */
+class CClickHouseHelper {
+
+	/**
+	 * Perform request(s) to Elasticsearch and parse the results.
+	 *
+	 * @param string $method      HTTP method to be used to perform request
+	 * @param string $endpoint    requested url
+	 * @param mixed  $request     data to be sent
+	 *
+	 * @return array    parsed result
+	 */
+	public static function query($request,$is_table_result,$columns) {
+		
+		global $HISTORY;
+//		error("CClikHouseHelper.query($request) ");
+		$ch = curl_init();
+
+		curl_setopt($ch, CURLOPT_URL,$HISTORY['url']);
+		curl_setopt($ch, CURLOPT_POST, 1);
+		curl_setopt($ch, CURLOPT_POSTFIELDS,$request);
+
+		// receive server response ...
+		curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
+
+		$server_output = curl_exec ($ch);
+		curl_close ($ch);
+
+//		error("Clickhouse returned '$server_output'");
+
+//		ob_start();
+//    		var_dump($request);
+//    		var_dump($server_output);
+
+//		$dresult = ob_get_clean();
+//	    error("Dump of the result is '$dresult'");
+
+//		file_put_contents('/var/log/nginx/clickhouse.log', "Clickhouse Results structure is $dresult' \n",FILE_APPEND);
+
+
+
+		return self::parseResult($server_output,$is_table_result,$columns);
+		
+	}
+
+	/**
+	 * Parse result and return two dimentional array of the result
+	 *
+	 * @param string $data        result as a string
+	 *
+	 * @return array    parsed result  two dimentional array of the result
+	 */
+	private static function parseResult($data,$is_table_result,$columns) {
+
+	    //to make processing simpler, lets distinguish results of two types - table (two dimensional array as result
+	    //returned or SINGLE, when one value (a number, probably) 
+	    if ($is_table_result) 
+	    {
+		$result=[];
+
+		$lines = explode("\n", $data);
+		$curline=0;
+
+		foreach ($lines as $line) {
+		    if (strlen(str_replace("\n",'',$line) ) > 0) 
+		    { 
+//			error("Processing line '$line'");
+//			error("Columns count is ".count($columns)." field count is ".count(explode("\t",$line)));
+			$result[$curline]=array_combine($columns,explode("\t",$line));
+			$curline++;
+
+		    } else {
+//			error("Got empty line, skipping");
+		    }
+		}
+
+	    } else
+	    {
+		//single result is here, stripping tabs,spaces and newlines
+		$result=str_replace(array("\r", "\n","\t"), '', $data);
+	    }
+
+/*	    ob_start();
+	    var_dump($result);
+	    $dresult = ob_get_clean();
+	    error("Dump of the result is '$dresult'");
+*/
+	    return $result;
+	}
+
+
+}
+
+
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php glaber/frontends/php/include/classes/macros/CMacrosResolverGeneral.php
--- zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/classes/macros/CMacrosResolverGeneral.php	2019-05-28 11:38:33.219895000 +0500
@@ -772,7 +772,7 @@
 		}
 
 		$result = DBselect(
-			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name'.
+			'SELECT f.triggerid,f.functionid,h.hostid,h.host,h.name,h.description'.
 			' FROM functions f'.
 				' JOIN items i ON f.itemid=i.itemid'.
 				' JOIN hosts h ON i.hostid=h.hostid'.
@@ -781,6 +781,7 @@
 
 		while ($row = DBfetch($result)) {
 			foreach ($macros[$row['functionid']] as $macro => $tokens) {
+				//var_dump($row);
 				switch ($macro) {
 					case 'HOST.ID':
 						$value = $row['hostid'];
@@ -794,6 +795,10 @@
 					case 'HOST.NAME':
 						$value = $row['name'];
 						break;
+					case 'HOST.DESCRIPTION1':
+						$value = $row['description'];
+						break;
+
 				}
 
 				foreach ($tokens as $token) {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolver.php glaber/frontends/php/include/classes/macros/CMacrosResolver.php
--- zabbix-4.0.1/frontends/php/include/classes/macros/CMacrosResolver.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/classes/macros/CMacrosResolver.php	2019-05-28 11:38:33.219895000 +0500
@@ -331,7 +331,7 @@
 
 		$types = [
 			'macros_n' => [
-				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}'],
+				'host' => ['{HOSTNAME}', '{HOST.HOST}', '{HOST.NAME}', '{HOST.DESCRIPTION1}'],
 				'interface' => ['{IPADDRESS}', '{HOST.IP}', '{HOST.DNS}', '{HOST.CONN}', '{HOST.PORT}'],
 				'item' => ['{ITEM.LASTVALUE}', '{ITEM.VALUE}']
 			],
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/defines.inc.php glaber/frontends/php/include/defines.inc.php
--- zabbix-4.0.1/frontends/php/include/defines.inc.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/defines.inc.php	2019-05-28 11:38:33.227895171 +0500
@@ -50,8 +50,10 @@
 
 // the maximum period to display history data for the latest data and item overview pages in seconds
 // by default set to 86400 seconds (24 hours)
-define('ZBX_HISTORY_PERIOD', 86400);
+define('ZBX_HISTORY_PERIOD', 7200);
 
+
+define('ZBX_HISTORY_SOURCE_CLICKHOUSE',	'clickhouse');
 define('ZBX_HISTORY_SOURCE_ELASTIC',	'elastic');
 define('ZBX_HISTORY_SOURCE_SQL',		'sql');
 
@@ -59,7 +61,7 @@
 define('ELASTICSEARCH_RESPONSE_AGGREGATION',	1);
 define('ELASTICSEARCH_RESPONSE_DOCUMENTS',		2);
 
-define('ZBX_WIDGET_ROWS', 20);
+define('ZBX_WIDGET_ROWS', 2000);
 
 define('ZBX_FONTPATH',				realpath('fonts')); // where to search for font (GD > 2.0.18)
 define('ZBX_GRAPH_FONT_NAME',		'DejaVuSans'); // font file name
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/frontends/php/include/hosts.inc.php glaber/frontends/php/include/hosts.inc.php
--- zabbix-4.0.1/frontends/php/include/hosts.inc.php	2018-10-29 22:36:02.000000000 +0500
+++ glaber/frontends/php/include/hosts.inc.php	2019-05-28 11:38:33.227895171 +0500
@@ -538,7 +538,6 @@
 
 	$hostIds = [];
 	$oldStatus = ($status == HOST_STATUS_MONITORED ? HOST_STATUS_NOT_MONITORED : HOST_STATUS_MONITORED);
-
 	$db_hosts = DBselect(
 		'SELECT h.hostid,h.host,h.status'.
 		' FROM hosts h'.
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/include/common.h glaber/include/common.h
--- zabbix-4.0.1/include/common.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/include/common.h	2019-05-28 11:38:33.319897145 +0500
@@ -87,6 +87,7 @@
 #define	AGENT_ERROR	-5
 #define	GATEWAY_ERROR	-6
 #define	CONFIG_ERROR	-7
+#define	NOT_PROCESSED	-8
 
 #define SUCCEED_OR_FAIL(result) (FAIL != (result) ? SUCCEED : FAIL)
 const char	*zbx_sysinfo_ret_string(int ret);
@@ -538,7 +539,9 @@
 #define ZBX_PROCESS_TYPE_ALERTMANAGER	25
 #define ZBX_PROCESS_TYPE_PREPROCMAN	26
 #define ZBX_PROCESS_TYPE_PREPROCESSOR	27
-#define ZBX_PROCESS_TYPE_COUNT		28	/* number of process types */
+#define ZBX_PROCESS_TYPE_ASYNC_SNMP	28
+#define ZBX_PROCESS_TYPE_ASYNC_AGENT	29
+#define ZBX_PROCESS_TYPE_COUNT		30	/* number of process types */
 #define ZBX_PROCESS_TYPE_UNKNOWN	255
 const char	*get_process_type_string(unsigned char process_type);
 int		get_process_type_by_name(const char *proc_type_str);
@@ -1524,5 +1527,8 @@
 #define ZBX_PROBLEM_SUPPRESSED_FALSE	0
 #define ZBX_PROBLEM_SUPPRESSED_TRUE	1
 
+#define ZBX_MIN_OPEN_FILES	16384
+#define ZBX_DESIRED_OPEN_FILES 65536
+
 #endif
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/include/dbcache.h glaber/include/dbcache.h
--- zabbix-4.0.1/include/dbcache.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/include/dbcache.h	2019-05-31 11:29:11.276895267 +0500
@@ -34,12 +34,17 @@
 #define	ZBX_POLLER_TYPE_IPMI		2
 #define	ZBX_POLLER_TYPE_PINGER		3
 #define	ZBX_POLLER_TYPE_JAVA		4
-#define	ZBX_POLLER_TYPE_COUNT		5	/* number of poller types */
+#define	ZBX_POLLER_TYPE_ASYNC_SNMP		5
+#define	ZBX_POLLER_TYPE_ASYNC_AGENT		6
+#define	ZBX_POLLER_TYPE_COUNT		7	/* number of poller types */
 
 #define MAX_JAVA_ITEMS		32
 #define MAX_SNMP_ITEMS		128
 #define MAX_POLLER_ITEMS	128	/* MAX(MAX_JAVA_ITEMS, MAX_SNMP_ITEMS) */
-#define MAX_PINGER_ITEMS	128
+#define MAX_PINGER_ITEMS	4096
+#define MAX_UNREACH_ITEMS		64 //we don't want this to be too big, but it's better for efficiency if thats more then one item 
+#define MAX_ASYNC_SNMP_ITEMS		1024
+#define MAX_ASYNC_AGENT_ITEMS		4096
 
 #define ZBX_TRIGGER_DEPENDENCY_LEVELS_MAX	32
 
@@ -485,6 +490,8 @@
 	unsigned char	flags;		/* see ZBX_DC_FLAG_* */
 	unsigned char	state;
 	int		ttl;		/* time-to-live of the history value */
+	char *host_name; /*hostname to log to history */
+	char *item_key; /* name of metric h*/
 }
 ZBX_DC_HISTORY;
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/include/zbxjson.h glaber/include/zbxjson.h
--- zabbix-4.0.1/include/zbxjson.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/include/zbxjson.h	2019-05-28 11:38:33.319897145 +0500
@@ -117,6 +117,7 @@
 #define ZBX_PROTO_VALUE_JAVA_GATEWAY_JMX	"java gateway jmx"
 #define ZBX_PROTO_VALUE_GET_QUEUE		"queue.get"
 #define ZBX_PROTO_VALUE_GET_STATUS		"status.get"
+#define ZBX_PROTO_VALUE_GET_PROBLEMS	"problems.get"
 #define ZBX_PROTO_VALUE_PROXY_DATA		"proxy data"
 #define ZBX_PROTO_VALUE_PROXY_TASKS		"proxy tasks"
 
@@ -146,6 +147,7 @@
 zbx_json_status_t;
 
 #define ZBX_JSON_STAT_BUF_LEN 4096
+#define ZBX_JSON_PROBLEMS_BUF_LEN 51200000
 
 struct zbx_json
 {
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/README.md glaber/README.md
--- zabbix-4.0.1/README.md	1970-01-01 05:00:00.000000000 +0500
+++ glaber/README.md	2019-05-28 11:38:33.115892769 +0500
@@ -0,0 +1,64 @@
+I am finally releasing the changes I did to make zabbix somewhat faster or let me say, better. Here the most important ones:
+
+    Before you start please make sure that the right reason to start using this code is your will to get some new experience or achieve an extraordinary results. It’s very likely something will break, won’t work and you will be the only one to deal with it (however I will be glad to answer some questions you might have). If you need strong and reliable production system, get a clean vanilla version of zabbix, buy a support.
+
+So, the short list of changes:
+
+    Clickhouse history offloading. Enjoy having data for years without MySQL/Postgress hassle at 50kNVPS.
+    Asynchronous SNMP processing. Beware! “Discovery” items will work the old slow synchronous way
+    Surprise… Asynchronous agent polling. Enjoy polling all your passive agents in a breeze. A couple of async agent polling threads will do all the work. Ok, ok, maybe 3 or 4 for really big installs (thousands of hosts)
+    And a Frankenstein – unreachable poller combines two worlds now – it will try async methods first and after failing them, will use old good sync methods.
+    Nmap accessibility checks. IPv4 only. Let me know if you need IPv6, and why.
+    Preproc manager with two sockets and queuing control. For those who monitors on really tight hardware.
+    Sorry guys, no “fast” widgets yet. They coming. A sort of. I just need to rethink a few points. However for “problems.get” message is working on server. Feel free to use it, and please note that you’ll get only the problems happened since the server start.
+    Proxy is not tested yet. We don’t use them anymore. No reason. But sure this is coming also.
+    Worker locks are fixed by zabbix team, thank you, Zabbix guys.
+
+First of all, what version ?
+
+The sources is zabbix-4.0.1rc2 The patch will work on both rc1 and rc2 and probably won’t on 4.0.0lts (there are nice cosmetic changes in main THREAD loops which make patch not compartible with it). However, good news: there is no DB upgrade needed, so you can go back/forward without db backup and rollback. Actually you should backup anyway, at least sometimes.
+Now, how to put it all together.
+
+First, download the sources:
+
+git clone https://github.com/miklert/zabbix.git
+
+Or the patch and original sources from https://zabbix.com/downloads/.
+
+Unpack, place patch (https://github.com/miklert/zabbix/blob/master/zabbix.patch) inside zabbix-4.0.Xxx folder and patch it:
+
+patch -p1 < the_patch
+
+Then configure, setup, prepare the usual way: https://www.zabbix.com/documentation/4.0/manual/installation/install
+And now, the part which is unique for this patched version:
+1. Set up asynchronous pollers:
+
+The two fellows are responsible for async SNMP and AGENT collection:
+
+StartPollersAsyncSNMP=10 StartPollersAsyncAGENT=10
+
+You don’t really need many of them. Typically they proccess 600-800 items a second: ./zabbix_server: async snmp poller #23 [got 8192 values in 13.841244 sec, getting values]
+
+Feel free to switch them off by setting =0, so zabbix_server will poll the usual way, using sync processing otherwise they will handle all whatever traffic they can handle.
+2. The Clickhouse setup.
+
+I’ve wrote a post someday: https://mmakurov.blogspot.com/2018/07/zabbix-clickhouse-details.html
+
+there is some problems you should know:
+
+    be prepared to have some data delay on graphs which depends on you data rates and clickhouse buffer sizes
+    zabbix server starts leaking when it reads str and txt data form history storage. I am trying to find reason for it, but for now fetching str and text values is disabled, but you can still save them and fetch from web ui.
+    Latest data panel will not show data dynamics (change in latest metrics to previously connects). You might want to remove the new code and uncomment the "original" version so it will work, but it's too slow for hosts that have more then a hundred items.
+
+3. Nmap:
+
+Zabbix server will use nmap for icmp* checks with packet count set to 1. If you need granular packet loss, say 58%, calculate it in triggers. And setup such an accessibility checks each 10-15 seconds
+
+Now, important note about delays: as items are processed in a bulk way (and also due to my laziness), they are coming back to queue altogether when all items has been polled. That takes 4-7 seconds in our setup. And a few seconds are needed to processing. So, don’t expect delays to be less then 10 seconds.
+
+However I would be interested to know if you do have such a requirements, perhaps, i’ll have a motivation to optimize it.
+4. No new widgets
+
+I really don’t want to release widgets yet as they are still in prototype stage and there is a big architecture problem – what they show is the only true since zabbix restart. I have two alternatives to fix that – either force zabbix_server on start to load all active problems from DB to memory or to ignore DB state on zabbix start and consider all triggers in OK state. Which will break problems start time. And there is really simple fix possible, so I will add separate fixed widgets soon.
+5. Proxy compiles, but I haven’t tested it at all.# zabbix
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxcommon/str.c glaber/src/libs/zbxcommon/str.c
--- zabbix-4.0.1/src/libs/zbxcommon/str.c	2018-10-29 22:36:01.000000000 +0500
+++ glaber/src/libs/zbxcommon/str.c	2019-05-28 11:38:33.335897488 +0500
@@ -1159,6 +1159,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return "poller";
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return "async snmp poller";
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return "async agent poller";
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return "unreachable poller";
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxcomms/comms.c glaber/src/libs/zbxcomms/comms.c
--- zabbix-4.0.1/src/libs/zbxcomms/comms.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxcomms/comms.c	2019-05-28 11:38:33.335897488 +0500
@@ -405,7 +405,10 @@
 		return FAIL;
 	}
 #else
-	if (ZBX_PROTO_ERROR == connect(s->socket, addr, addrlen))
+	//on non-block socket it's ok to get an error, but the socket 
+	//should be in the connect progress state
+	if (ZBX_PROTO_ERROR == connect(s->socket, addr, addrlen) && 
+			( 0 != timeout | EINPROGRESS != errno ) )
 	{
 		*error = zbx_strdup(*error, strerror_from_system(zbx_socket_last_error()));
 		return FAIL;
@@ -439,6 +442,11 @@
 	struct addrinfo	*ai_bind = NULL;
 	char		service[8], *error = NULL;
 	void		(*func_socket_close)(zbx_socket_t *s);
+	
+	if ( 0 == timeout ) {
+		//assuming async operations when no timeout is set
+		type = type | SOCK_NONBLOCK;
+	}
 
 	if (SOCK_DGRAM == type && (ZBX_TCP_SEC_TLS_CERT == tls_connect || ZBX_TCP_SEC_TLS_PSK == tls_connect))
 	{
@@ -550,6 +558,11 @@
 	char		*error = NULL;
 	void		(*func_socket_close)(zbx_socket_t *s);
 
+	if ( 0 == timeout ) {
+		//assuming async operations when no timeout is set
+		type = type | SOCK_NONBLOCK;
+	}
+
 	if (SOCK_DGRAM == type && (ZBX_TCP_SEC_TLS_CERT == tls_connect || ZBX_TCP_SEC_TLS_PSK == tls_connect))
 	{
 		THIS_SHOULD_NEVER_HAPPEN;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxdbcache/dbcache.c glaber/src/libs/zbxdbcache/dbcache.c
--- zabbix-4.0.1/src/libs/zbxdbcache/dbcache.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxdbcache/dbcache.c	2019-05-31 11:29:11.280895355 +0500
@@ -2546,6 +2546,10 @@
 			h->flags |= ZBX_DC_FLAG_NOTRENDS;
 		}
 
+		h->host_name = item->host.host;
+		//todo: need to see if the item key actually needs macro processing first
+		h->item_key = item->key_orig;
+
 		normalize_item_value(item, h);
 
 		diff = calculate_item_update(item, h);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.c glaber/src/libs/zbxdbcache/dbconfig.c
--- zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxdbcache/dbconfig.c	2019-05-28 11:38:33.339897573 +0500
@@ -90,6 +90,8 @@
 
 extern unsigned char	program_type;
 extern int		CONFIG_TIMER_FORKS;
+extern int CONFIG_ASYNC_AGENT_POLLER_FORKS;
+extern int CONFIG_ASYNC_SNMP_POLLER_FORKS;
 
 ZBX_MEM_FUNC_IMPL(__config, config_mem)
 
@@ -187,7 +189,7 @@
 	return ret;
 }
 
-static unsigned char	poller_by_item(unsigned char type, const char *key)
+static unsigned char	poller_by_item(unsigned char type, const char *key, zbx_uint64_t itemid)
 {
 	switch (type)
 	{
@@ -202,10 +204,7 @@
 				return ZBX_POLLER_TYPE_PINGER;
 			}
 			/* break; is not missing here */
-		case ITEM_TYPE_ZABBIX:
-		case ITEM_TYPE_SNMPv1:
-		case ITEM_TYPE_SNMPv2c:
-		case ITEM_TYPE_SNMPv3:
+
 		case ITEM_TYPE_INTERNAL:
 		case ITEM_TYPE_AGGREGATE:
 		case ITEM_TYPE_EXTERNAL:
@@ -218,6 +217,44 @@
 				break;
 
 			return ZBX_POLLER_TYPE_NORMAL;
+		
+		case ITEM_TYPE_ZABBIX:
+			if (0 == CONFIG_ASYNC_AGENT_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			}
+			return ZBX_POLLER_TYPE_ASYNC_AGENT;
+
+		case ITEM_TYPE_SNMPv1:
+		case ITEM_TYPE_SNMPv2c:
+		case ITEM_TYPE_SNMPv3:
+			if (0 == CONFIG_ASYNC_SNMP_POLLER_FORKS ){
+				if (0 == CONFIG_POLLER_FORKS)
+					break;
+
+				return ZBX_POLLER_TYPE_NORMAL;
+			} else {
+				ZBX_DC_SNMPITEM *snmpitem;
+
+				//need to see if this statical oid snmp item or a dynamic one
+				snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &itemid);
+				if (NULL == snmpitem ) 
+						return ZBX_POLLER_TYPE_NORMAL;
+
+				
+
+				if ( 0 == strncmp(snmpitem->snmp_oid, "discovery[", 10) || 
+						NULL != strchr(snmpitem->snmp_oid, '[') )
+				{
+					zabbix_log(LOG_LEVEL_DEBUG,"Selecting normal poller for dynamic item snmp  %s",snmpitem->snmp_oid);
+					return ZBX_POLLER_TYPE_NORMAL;
+				} else {
+					return ZBX_POLLER_TYPE_ASYNC_SNMP;
+				}
+			}
+
 		case ITEM_TYPE_IPMI:
 			if (0 == CONFIG_IPMIPOLLER_FORKS)
 				break;
@@ -400,7 +437,7 @@
 		return;
 	}
 
-	poller_type = poller_by_item(dc_item->type, dc_item->key);
+	poller_type = poller_by_item(dc_item->type, dc_item->key, dc_item->itemid);
 
 	if (0 != (flags & ZBX_HOST_UNREACHABLE))
 	{
@@ -5651,6 +5688,8 @@
 	CREATE_HASHSET(config->corr_conditions, 0);
 	CREATE_HASHSET(config->corr_operations, 0);
 	CREATE_HASHSET(config->hostgroups, 0);
+	CREATE_HASHSET(config->problems, 0);
+
 	zbx_vector_ptr_create_ext(&config->hostgroups_name, __config_mem_malloc_func, __config_mem_realloc_func,
 			__config_mem_free_func);
 
@@ -7602,6 +7641,18 @@
 		case ZBX_POLLER_TYPE_PINGER:
 			max_items = MAX_PINGER_ITEMS;
 			break;
+		case ZBX_POLLER_TYPE_NORMAL:
+			max_items = 1;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_SNMP:
+			max_items = MAX_ASYNC_SNMP_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_UNREACHABLE:
+			max_items = MAX_UNREACH_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_AGENT:
+			max_items = MAX_ASYNC_AGENT_ITEMS;
+			break;
 		default:
 			max_items = 1;
 	}
@@ -7619,22 +7670,18 @@
 		min = zbx_binary_heap_find_min(queue);
 		dc_item = (ZBX_DC_ITEM *)min->data;
 
+
 		if (dc_item->nextcheck > now)
 			break;
-
-		if (0 != num)
-		{
-			if (SUCCEED == is_snmp_type(dc_item_prev->type))
-			{
-				if (0 != __config_snmp_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-			else if (ITEM_TYPE_JMX == dc_item_prev->type)
-			{
-				if (0 != __config_java_item_compare(dc_item_prev, dc_item))
-					break;
-			}
-		}
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_NORMAL == poller_type ) && (SUCCEED == is_snmp_type(dc_item_prev->type))
+					 && (0 != __config_snmp_item_compare(dc_item_prev, dc_item)) )
+			break;
+		
+		
+		if ( (0 != num) && 	( ZBX_POLLER_TYPE_JAVA == poller_type )	&& (ITEM_TYPE_JMX == dc_item_prev->type) && 
+				(0 != __config_java_item_compare(dc_item_prev, dc_item)) )
+			break;
 
 		zbx_binary_heap_remove_min(queue);
 		dc_item->location = ZBX_LOC_NOWHERE;
@@ -7652,34 +7699,41 @@
 		}
 
 		/* don't apply unreachable item/host throttling for prioritized items */
-		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority)
-		{
-			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
-			{
-				/* move reachable items on reachable hosts to normal pollers */
-				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
-						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
-					continue;
-				}
-			}
-			else
-			{
-				/* move items on unreachable hosts to unreachable pollers or    */
-				/* postpone checks on hosts that have been checked recently and */
-				/* are still unreachable                                        */
-				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
-						disable_until > now)
-				{
-					dc_requeue_item(dc_item, dc_host, dc_item->state,
-							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
-					continue;
-				}
-
-				DCincrease_disable_until(dc_item, dc_host, now);
-			}
-		}
+		/* and for async and unreachable pollers */
+		
+		//in async polling model there is NO problems with checking whatever we want
+		//whenever we want, so no prioritization required at all
+		//in fact, there is even no reason to pause quering such an items
+		
+//		if (ZBX_QUEUE_PRIORITY_HIGH != dc_item->queue_priority && ZBX_POLLER_TYPE_ASYNC != poller_type 
+//										&& ZBX_POLLER_TYPE_UNREACHABLE != poller_type)
+//		{
+//			if (0 == (disable_until = DCget_disable_until(dc_item, dc_host)))
+//			{
+//				/* move reachable items on reachable hosts to normal pollers */
+//				if (ZBX_POLLER_TYPE_UNREACHABLE == poller_type &&
+//						ZBX_QUEUE_PRIORITY_LOW != dc_item->queue_priority)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state, ZBX_ITEM_COLLECTED, now);
+//					continue;
+//				}
+//			}
+//			else
+//			{
+//				/* move items on unreachable hosts to unreachable pollers or    */
+//				/* postpone checks on hosts that have been checked recently and */
+//				/* are still unreachable                                        */
+//				if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_JAVA == poller_type ||
+//						disable_until > now)
+//				{
+//					dc_requeue_item(dc_item, dc_host, dc_item->state,
+//							ZBX_ITEM_COLLECTED | ZBX_HOST_UNREACHABLE, now);
+//					continue;
+//				}
+//
+//				DCincrease_disable_until(dc_item, dc_host, now);
+//			}
+//		}
 
 		dc_item_prev = dc_item;
 		dc_item->location = ZBX_LOC_POLLER;
@@ -7687,21 +7741,22 @@
 		DCget_item(&items[num], dc_item);
 		num++;
 
-		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
-				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
-		{
-			ZBX_DC_SNMPITEM	*snmpitem;
+		//the following code never works anyway as MAX_SNMP_ITEMS is one for regular pollers
 
-			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
-
-			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
-					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
-			{
-				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
-			}
-		}
+//		if (1 == num && ZBX_POLLER_TYPE_NORMAL == poller_type && SUCCEED == is_snmp_type(dc_item->type) &&
+//				0 == (ZBX_FLAG_DISCOVERY_RULE & dc_item->flags))
+//		{
+//			ZBX_DC_SNMPITEM	*snmpitem;
+//
+//			snmpitem = (ZBX_DC_SNMPITEM *)zbx_hashset_search(&config->snmpitems, &dc_item->itemid);
+//
+//			if (ZBX_SNMP_OID_TYPE_NORMAL == snmpitem->snmp_oid_type ||
+//					ZBX_SNMP_OID_TYPE_DYNAMIC == snmpitem->snmp_oid_type)
+//			{
+//				max_items = DCconfig_get_suggested_snmp_vars_nolock(dc_item->interfaceid, NULL);
+//			}
+//		}
 	}
-
 	UNLOCK_CACHE;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
@@ -7954,6 +8009,7 @@
 				dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
 				break;
 			case NETWORK_ERROR:
+			case NOT_PROCESSED:
 			case GATEWAY_ERROR:
 			case TIMEOUT_ERROR:
 				dc_item->queue_priority = ZBX_QUEUE_PRIORITY_LOW;
@@ -7961,11 +8017,48 @@
 						time(NULL));
 				break;
 			default:
+				zabbix_log(LOG_LEVEL_INFORMATION,"Unknown errcode: %d", errcodes[i]);
 				THIS_SHOULD_NEVER_HAPPEN;
 		}
 	}
 }
 
+static void	dc_requeue_async_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
+		const int *errcodes, size_t num)
+{
+	size_t		i;
+	ZBX_DC_ITEM	*dc_item;
+	ZBX_DC_HOST	*dc_host;
+
+	for (i = 0; i < num; i++)
+	{
+		if (FAIL == errcodes[i])
+			continue;
+
+		if (NULL == (dc_item = (ZBX_DC_ITEM *)zbx_hashset_search(&config->items, &itemids[i])))
+			continue;
+
+		if (ZBX_LOC_POLLER == dc_item->location)
+			dc_item->location = ZBX_LOC_NOWHERE;
+
+		if (ITEM_STATUS_ACTIVE != dc_item->status)
+			continue;
+
+		if (NULL == (dc_host = (ZBX_DC_HOST *)zbx_hashset_search(&config->hosts, &dc_item->hostid)))
+			continue;
+
+		if (HOST_STATUS_MONITORED != dc_host->status)
+			continue;
+
+		if (SUCCEED != is_counted_in_item_queue(dc_item->type, dc_item->key))
+			continue;
+
+		//whatever the other return codes, we want the item to be polled again
+		dc_requeue_item(dc_item, dc_host, states[i], ZBX_ITEM_COLLECTED, lastclocks[i]);
+	}
+}
+
+
 void	DCrequeue_items(const zbx_uint64_t *itemids, const unsigned char *states, const int *lastclocks,
 		const int *errcodes, size_t num)
 {
@@ -7980,13 +8073,17 @@
 		const int *errcodes, size_t num, unsigned char poller_type, int *nextcheck)
 {
 	WRLOCK_CACHE;
-
-	dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	if (ZBX_POLLER_TYPE_ASYNC_AGENT == poller_type || ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type) {
+		dc_requeue_async_items(itemids, states, lastclocks, errcodes, num);	
+	} else {
+		dc_requeue_items(itemids, states, lastclocks, errcodes, num);
+	}
 	*nextcheck = dc_config_get_queue_nextcheck(&config->queues[poller_type]);
 
 	UNLOCK_CACHE;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: zbx_dc_requeue_unreachable_items                                 *
@@ -11773,4 +11870,4 @@
 	}
 
 	UNLOCK_CACHE;
-}
+}
\ В конце файла нет новой строки
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.h glaber/src/libs/zbxdbcache/dbconfig.h
--- zabbix-4.0.1/src/libs/zbxdbcache/dbconfig.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxdbcache/dbconfig.h	2019-05-28 11:38:33.339897573 +0500
@@ -760,9 +760,33 @@
 	ZBX_DC_CONFIG_TABLE	*config;
 	ZBX_DC_STATUS		*status;
 	zbx_hashset_t		strpool;
+	zbx_hashset_t		problems;
 }
 ZBX_DC_CONFIG;
 
+typedef struct
+{
+	zbx_uint64_t 	eventid;
+	char 			description[512];
+	unsigned int 	lastupdate;
+	unsigned int 	state;
+}
+ZBX_DC_PROBLEM;
+
+/* problem in memory cache-related defines */
+
+/* how often to run in memory problems cleanup */
+#define ZBX_PROBLEM_CLEAN_RUN 120 
+
+#define ZBX_PROBLEM_CLOSED	0
+#define ZBX_PROBLEM_OPEN	1
+
+/* delete problems from memory that's been there for more then 1 month */
+#define ZBX_PROBLEM_OPEN_TIMEOUT	30*86400
+/* and keep closed problems only for 1 hour */
+#define ZBX_PROBLEM_CLOSED_TIMEOUT	30
+
+
 extern int	sync_in_progress;
 extern ZBX_DC_CONFIG	*config;
 extern zbx_rwlock_t	config_lock;
@@ -824,5 +848,4 @@
 #define ZBX_MAINTENANCE_UPDATE_FLAGS_NUM()	\
 		((CONFIG_TIMER_FORKS + sizeof(uint64_t) * 8 - 1) / (sizeof(uint64_t) * 8))
 
-
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxhistory/history.c glaber/src/libs/zbxhistory/history.c
--- zabbix-4.0.1/src/libs/zbxhistory/history.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxhistory/history.c	2019-05-28 11:38:33.347897745 +0500
@@ -25,10 +25,11 @@
 
 #include "../zbxalgo/vectorimpl.h"
 
-ZBX_VECTOR_IMPL(history_record, zbx_history_record_t)
+ZBX_VECTOR_IMPL(history_record, zbx_history_record_t);
 
 extern char	*CONFIG_HISTORY_STORAGE_URL;
 extern char	*CONFIG_HISTORY_STORAGE_OPTS;
+extern char	*CONFIG_HISTORY_STORAGE_TYPE;
 
 zbx_history_iface_t	history_ifaces[ITEM_VALUE_TYPE_MAX];
 
@@ -53,10 +54,21 @@
 
 	for (i = 0; i < ITEM_VALUE_TYPE_MAX; i++)
 	{
-		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i]))
+		if (NULL == CONFIG_HISTORY_STORAGE_URL || NULL == strstr(CONFIG_HISTORY_STORAGE_OPTS, opts[i])) 
+		{
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init SQL storage engine as history storage for type %s", opts[i]);
 			ret = zbx_history_sql_init(&history_ifaces[i], i, error);
-		else
+		}
+		else if ( NULL != strstr(CONFIG_HISTORY_STORAGE_TYPE,"clickhouse")) 
+		{
+			ret = zbx_history_clickhouse_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init Clickhouse storage engine as history storage for type %s", opts[i]);
+		}
+		else 
+		{
 			ret = zbx_history_elastic_init(&history_ifaces[i], i, error);
+			zabbix_log(LOG_LEVEL_INFORMATION, "Init ElasticsSearch storage engine as history storage for type %s", opts[i]);
+		}
 
 		if (FAIL == ret)
 			return FAIL;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c glaber/src/libs/zbxhistory/history_clickhouse.c
--- zabbix-4.0.1/src/libs/zbxhistory/history_clickhouse.c	1970-01-01 05:00:00.000000000 +0500
+++ glaber/src/libs/zbxhistory/history_clickhouse.c	2019-05-31 11:29:11.280895355 +0500
@@ -0,0 +1,551 @@
+/*
+** Zabbix
+** Copyright (C) 2001-2018 Zabbix SIA
+**
+** This program is free software; you can redistribute it and/or modify
+** it under the terms of the GNU General Public License as published by
+** the Free Software Foundation; either version 2 of the License, or
+** (at your option) any later version.
+**
+** This program is distributed in the hope that it will be useful,
+** but WITHOUT ANY WARRANTY; without even the implied warranty of
+** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+** GNU General Public License for more details.
+**
+** You should have received a copy of the GNU General Public License
+** along with this program; if not, write to the Free Software
+** Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+**/
+
+#include "common.h"
+#include "log.h"
+#include "zbxjson.h"
+#include "zbxalgo.h"
+#include "dbcache.h"
+#include "zbxhistory.h"
+#include "zbxself.h"
+#include "history.h"
+
+/* curl_multi_wait() is supported starting with version 7.28.0 (0x071c00) */
+#if defined(HAVE_LIBCURL) && LIBCURL_VERSION_NUM >= 0x071c00
+
+extern char	*CONFIG_HISTORY_STORAGE_URL;
+extern int	CONFIG_HISTORY_STORAGE_PIPELINES;
+extern char *CONFIG_HISTORY_STORAGE_TABLE_NAME;
+extern int CONFIG_CLICKHOUSE_SAVE_HOST_AND_METRIC_NAME;
+extern int CONFIG_CLICKHOUSE_SAVE_NS_VALUE;
+extern char *CONFIG_CLICKHOUSE_USERNAME;
+extern char *CONFIG_CLICKHOUSE_PASSWORD;
+extern int CONFIG_SERVER_STARTUP_TIME;
+extern int CONFIG_CLICKHOUSE_VALUECACHE_FILL_TIME;
+
+typedef struct
+{
+	char	*url;
+	char	*buf;
+}
+zbx_clickhouse_data_t;
+
+typedef struct
+{
+	char	*data;
+	size_t	alloc;
+	size_t	offset;
+}
+zbx_httppage_t;
+
+static size_t	curl_write_cb(void *ptr, size_t size, size_t nmemb, void *userdata)
+{
+	size_t	r_size = size * nmemb;
+
+	zbx_httppage_t	*page = (zbx_httppage_t	*)userdata;
+	zbx_strncpy_alloc(&page->data, &page->alloc, &page->offset, ptr, r_size);
+
+	return r_size;
+}
+
+static history_value_t	history_str2value(char *str, unsigned char value_type)
+{
+	history_value_t	value;
+
+	switch (value_type)
+	{
+		case ITEM_VALUE_TYPE_LOG:
+			value.log = (zbx_log_value_t *)zbx_malloc(NULL, sizeof(zbx_log_value_t));
+			memset(value.log, 0, sizeof(zbx_log_value_t));
+			value.log->value = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_STR:
+		case ITEM_VALUE_TYPE_TEXT:
+			value.str = zbx_strdup(NULL, str);
+			break;
+		case ITEM_VALUE_TYPE_FLOAT:
+			value.dbl = atof(str);
+			break;
+		case ITEM_VALUE_TYPE_UINT64:
+			ZBX_STR2UINT64(value.ui64, str);
+			break;
+	}
+
+	return value;
+}
+
+static void	clickhouse_log_error(CURL *handle, CURLcode error, const char *errbuf,zbx_httppage_t *page_r)
+{curl_easy_cleanup(handle);
+	long	http_code;
+
+	if (CURLE_HTTP_RETURNED_ERROR == error)
+	{
+		curl_easy_getinfo(handle, CURLINFO_RESPONSE_CODE, &http_code);
+		if (0 != page_r->offset)
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhouse, HTTP error: %ld, message: %s",
+					http_code, page_r->data);
+		}
+		else
+			zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhousesearch, HTTP error: %ld", http_code);
+	}
+	else
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot get values from clickhousesearch: %s",
+				'\0' != *errbuf ? errbuf : curl_easy_strerror(error));
+	}
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_close                                                          *
+ *                                                                                  *
+ * Purpose: closes connection and releases allocated resources                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_close(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+
+	zbx_free(data->buf);
+}
+
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_destroy                                                        *
+ *                                                                                  *
+ * Purpose: destroys history storage interface                                      *
+ *                                                                                  *
+ * Parameters:  hist - [IN] the history storage interface                           *
+ *                                                                                  *
+ ************************************************************************************/
+static void	clickhouse_destroy(zbx_history_iface_t *hist)
+{
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+
+	clickhouse_close(hist);
+
+	zbx_free(data->url);
+	zbx_free(data);
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_get_values                                                     *
+ *                                                                                  *
+ * Purpose: gets item history data from history storage                             *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              itemid  - [IN] the itemid                                           *
+ *              start   - [IN] the period start timestamp                           *
+ *              count   - [IN] the number of values to read                         *
+ *              end     - [IN] the period end timestamp                             *
+ *              values  - [OUT] the item history data values                        *
+ *                                                                                  *
+ * Return value: SUCCEED - the history data were read successfully                  *
+ *               FAIL - otherwise                                                   *
+ *                                                                                  *
+ * Comments: This function reads <count> values from ]<start>,<end>] interval or    *
+ *           all values from the specified interval if count is zero.               *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_get_values(zbx_history_iface_t *hist, zbx_uint64_t itemid, int start, int count, int end,
+		zbx_vector_history_record_t *values)
+{
+	const char		*__function_name = "clickhouse_get_values";
+	int valuecount=0;
+
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+	size_t			url_alloc = 0, url_offset = 0;
+    
+	CURLcode		err;
+	CURL	*handle = NULL;
+	
+	struct curl_slist	*curl_headers = NULL;
+	
+    char  errbuf[CURL_ERROR_SIZE];
+    char	*sql_buffer=NULL;
+    size_t			buf_alloc = 0, buf_offset = 0;
+    zbx_httppage_t page_r;
+ 
+	zbx_history_record_t	hr;
+
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+
+    bzero(&page_r,sizeof(zbx_httppage_t));
+
+	
+//    if (time(NULL)- CONFIG_CLICKHOUSE_VALUECACHE_FILL_TIME < CONFIG_SERVER_STARTUP_TIME) {
+//		
+//		zabbix_log(LOG_LEVEL_DEBUG, "waiting for cache load, exiting");
+//      goto out;
+//	}
+
+	if (NULL == (handle = curl_easy_init()))
+	{
+		zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		goto out;
+	} 
+	
+	 zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, 
+			"SELECT  toUInt32(clock) clock,ns,value,value_dbl,value_str");
+
+	if (CONFIG_CLICKHOUSE_SAVE_NS_VALUE) {
+		zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, ",ns");
+	}
+	
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, " FROM %s WHERE itemid=%ld ",
+		CONFIG_HISTORY_STORAGE_TABLE_NAME,itemid);
+
+	if (1 == end-start) {
+		zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock = %d ", end);
+	} else {
+		if (0 < start) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock > %d ", start);
+		}
+		if (0 < end ) {
+			zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "AND clock <= %d ", end);
+		}
+	}
+
+	zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "ORDER BY clock DESC ");
+
+	if (0 < count) 
+	{
+	    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "LIMIT %d ", count);
+	}
+
+    zbx_snprintf_alloc(&sql_buffer, &buf_alloc, &buf_offset, "format JSON ");
+
+	zabbix_log(LOG_LEVEL_DEBUG, "CLICKHOUSE: sending query to clickhouse: %s", sql_buffer);
+
+	curl_easy_setopt(handle, CURLOPT_URL, data->url);
+	curl_easy_setopt(handle, CURLOPT_POSTFIELDS, sql_buffer);
+	curl_easy_setopt(handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+	curl_easy_setopt(handle, CURLOPT_WRITEDATA, &page_r);
+	curl_easy_setopt(handle, CURLOPT_HTTPHEADER, curl_headers);
+	curl_easy_setopt(handle, CURLOPT_FAILONERROR, 1L);
+	curl_easy_setopt(handle, CURLOPT_ERRORBUFFER, errbuf);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "sending query to %s; post data: %s", data->url, sql_buffer);
+
+	page_r.offset = 0;
+	*errbuf = '\0';
+
+	if (CURLE_OK != (err = curl_easy_perform(handle)))
+	{
+		clickhouse_log_error(handle, err, errbuf,&page_r);
+        zabbix_log(LOG_LEVEL_WARNING, "Failed query '%s'", sql_buffer);
+		goto out;
+	}
+
+    zabbix_log(LOG_LEVEL_DEBUG, "recieved from clickhouse: %s", page_r.data);
+		
+    struct zbx_json_parse	jp, jp_row, jp_data;
+	const char		*p = NULL;
+    
+    zbx_json_open(page_r.data, &jp);
+    zbx_json_brackets_by_name(&jp, "data", &jp_data);
+    
+    while (NULL != (p = zbx_json_next(&jp_data, p)))
+	{
+        char *itemid=NULL;
+        char *clck = NULL, *ns = NULL, *value = NULL, *value_dbl = NULL, *value_str = NULL;
+        size_t clck_alloc=0, ns_alloc = 0, value_alloc = 0, value_dbl_alloc = 0, value_str_alloc = 0;
+        struct zbx_json_parse	jp_row;
+
+        if (SUCCEED == zbx_json_brackets_open(p, &jp_row)) {
+			
+            if (SUCCEED == zbx_json_value_by_name_dyn(&jp_row, "clock", &clck, &clck_alloc) &&
+                SUCCEED == zbx_json_value_by_name_dyn(&jp_row, "value", &value, &value_alloc) &&
+                SUCCEED == zbx_json_value_by_name_dyn(&jp_row, "value_dbl", &value_dbl, &value_dbl_alloc) &&
+                SUCCEED == zbx_json_value_by_name_dyn(&jp_row, "value_str", &value_str, &value_str_alloc)) 
+            {
+               
+			   	if ( CONFIG_CLICKHOUSE_SAVE_NS_VALUE &&
+					 SUCCEED == zbx_json_value_by_name_dyn(&jp_row, "ns", &ns, &ns_alloc) ) {
+							hr.timestamp.ns = atoi(ns); 
+				} else hr.timestamp.ns = 0;
+
+               	hr.timestamp.sec = atoi(clck);
+				zabbix_log(LOG_LEVEL_DEBUG,"CLICKHOSUE read: Clock: %s, ns: %s, value: %s, value_dbl: %s, value_str:%s ",clck,ns,value,value_dbl,value_str);
+
+                switch (hist->value_type)
+				{
+					case ITEM_VALUE_TYPE_UINT64:
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as UINT64 %s",value);
+			    		hr.value = history_str2value(value, hist->value_type);
+						zbx_vector_history_record_append_ptr(values, &hr);
+						break;
+
+					case ITEM_VALUE_TYPE_FLOAT: 
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as DBL field %s",value_dbl);
+			    		hr.value = history_str2value(value_dbl, hist->value_type);
+                        zbx_vector_history_record_append_ptr(values, &hr);
+						break;
+					case ITEM_VALUE_TYPE_STR:
+					case ITEM_VALUE_TYPE_TEXT:
+
+						zabbix_log(LOG_LEVEL_DEBUG, "Parsed  as STR/TEXT type %s",value_str);
+						hr.value = history_str2value(value_str, hist->value_type);
+                        zbx_vector_history_record_append_ptr(values, &hr);
+                        break;
+
+					case ITEM_VALUE_TYPE_LOG:
+						//todo: does server really need's to read logs????
+                        break;
+				}				
+				
+				valuecount++;
+			} 
+            
+        } else {
+            zabbix_log(LOG_LEVEL_DEBUG,"CLICCKHOUSE: Couldn't parse JSON row: %s",p);
+        };
+
+		if ( !valuecount) zabbix_log(LOG_LEVEL_DEBUG,"No data returned form request");
+        zbx_free(clck);
+        zbx_free(ns);
+        zbx_free(value);
+        zbx_free(value_dbl);
+        zbx_free(value_str);            
+    } 
+out:
+	clickhouse_close(hist);
+	curl_easy_cleanup(handle);
+	curl_slist_free_all(curl_headers);
+    zbx_free(sql_buffer);
+    zbx_free(page_r.data);
+
+	zbx_vector_history_record_sort(values, (zbx_compare_func_t)zbx_history_record_compare_desc_func);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+	//retrun succeed ander any circumstances 
+	//since otherwise history sincers will try to repeate the query 
+	//and will cause additional memory consumption (i suspect in the curl libriary code)
+	return SUCCEED;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_add_values                                                     *
+ *                                                                                  *
+ * Purpose: sends history data to the storage                                       *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *              history - [IN] the history data vector (may have mixed value types) *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_add_values(zbx_history_iface_t *hist, const zbx_vector_ptr_t *history)
+{
+	const char	*__function_name = "clickhouse_add_values";
+
+	zbx_clickhouse_data_t	*data = (zbx_clickhouse_data_t *)hist->data;
+	int			i,j, num = 0;
+	ZBX_DC_HISTORY		*h;
+	struct zbx_json		json_idx, json;
+	size_t			buf_alloc = 0, buf_offset = 0;
+	
+    char *sql_buffer=NULL;	
+	size_t sql_alloc=0, sql_offset=0;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+    
+	zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,"INSERT INTO %s (day,itemid,clock,value,value_dbl,value_str", CONFIG_HISTORY_STORAGE_TABLE_NAME);
+
+	if ( CONFIG_CLICKHOUSE_SAVE_NS_VALUE ) {
+		zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,",ns");
+	}
+	
+	zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,") VALUES");
+
+	for (i = 0; i < history->values_num; i++)
+	{
+		h = (ZBX_DC_HISTORY *)history->values[i];
+			
+		if (hist->value_type != h->value_type)	
+			continue;
+		
+		//common part
+		zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,"(CAST(%d as date) ,%ld,%d",
+				h->ts.sec,h->itemid,h->ts.sec);
+    	
+		//type-dependent part
+		if (ITEM_VALUE_TYPE_UINT64 == h->value_type) 
+	           zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,",%ld,0,''",h->value.ui64);
+    	
+		if (ITEM_VALUE_TYPE_FLOAT == h->value_type) 
+           zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,",0,%f,''",h->value.dbl);
+        
+
+		if (ITEM_VALUE_TYPE_STR == h->value_type || ITEM_VALUE_TYPE_TEXT == h->value_type ) {
+		    		
+            //todo: make more sensible string quotation
+            for (j = 0; j < strlen(h->value.str); j++) {
+		        if ('\'' == h->value.str[j]) { 
+				    h->value.str[j]=' ';
+			    }
+			}
+		    zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,",0,0,'%s'",h->value.str);
+		}
+		//todo: log writing support: must be done in separate table unlike other values
+		//if (ITEM_VALUE_TYPE_LOG == h->value_type)
+		//{
+		//    const zbx_log_value_t	*log;
+		//    log = h->value.log;
+		//}
+
+		if ( CONFIG_CLICKHOUSE_SAVE_NS_VALUE) {
+			zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,",%d", h->ts.ns);
+		}
+		
+		zbx_snprintf_alloc(&sql_buffer,&sql_alloc,&sql_offset,"),");
+
+		num++;
+	}
+
+	if (num > 0)
+	{ 
+    
+		zbx_httppage_t	page_r;
+		bzero(&page_r,sizeof(zbx_httppage_t));
+		struct curl_slist	*curl_headers = NULL;
+		char  errbuf[CURL_ERROR_SIZE];
+		CURLcode		err;
+		CURL	*handle = NULL;
+		
+		if (NULL == (handle = curl_easy_init()))
+		{
+			zabbix_log(LOG_LEVEL_ERR, "cannot initialize cURL session");
+		} else {
+
+			curl_easy_setopt(handle, CURLOPT_URL, data->url);
+			curl_easy_setopt(handle, CURLOPT_POSTFIELDS, sql_buffer);
+			curl_easy_setopt(handle, CURLOPT_WRITEFUNCTION, curl_write_cb);
+			curl_easy_setopt(handle, CURLOPT_WRITEDATA, page_r);
+			curl_easy_setopt(handle, CURLOPT_HTTPHEADER, curl_headers);
+			curl_easy_setopt(handle, CURLOPT_FAILONERROR, 1L);
+			curl_easy_setopt(handle, CURLOPT_ERRORBUFFER, errbuf);
+	
+			if (CURLE_OK != (err = curl_easy_perform(handle)))
+			{
+				clickhouse_log_error(handle, err, errbuf,&page_r);
+        		zabbix_log(LOG_LEVEL_WARNING, "Failed query '%s'", sql_buffer);
+	
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "CLICKHOUSE: succeeded query: %s",sql_buffer);
+			}
+		}
+		
+		
+	 	zbx_free(page_r.data);
+		curl_slist_free_all(curl_headers);
+		curl_easy_cleanup(handle);
+	}
+
+	zbx_free(sql_buffer);
+	
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
+
+	return num;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: clickhouse_flush                                                          *
+ *                                                                                  *
+ * Purpose: flushes the history data to storage                                     *
+ *                                                                                  *
+ * Parameters:  hist    - [IN] the history storage interface                        *
+ *                                                                                  *
+ * Comments: This function will try to flush the data until it succeeds or          *
+ *           unrecoverable error occurs                                             *
+ *                                                                                  *
+ ************************************************************************************/
+static int	clickhouse_flush(zbx_history_iface_t *hist)
+{
+	ZBX_UNUSED(hist);
+	return SUCCEED;
+}
+
+/************************************************************************************
+ *                                                                                  *
+ * Function: zbx_history_clickhouse_init                                               *
+ *                                                                                  *
+ * Purpose: initializes history storage interface                                   *
+ *                                                                                  *
+ * Parameters:  hist       - [IN] the history storage interface                     *
+ *              value_type - [IN] the target value type                             *
+ *              error      - [OUT] the error message                                *
+ *                                                                                  *
+ * Return value: SUCCEED - the history storage interface was initialized            *
+ *               FAIL    - otherwise                                                *
+ *                                                                                  *
+ ************************************************************************************/
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	zbx_clickhouse_data_t	*data;
+	size_t alloc = 0, offset = 0;
+	if (0 != curl_global_init(CURL_GLOBAL_ALL))
+	{
+		*error = zbx_strdup(*error, "Cannot initialize cURL library");
+		return FAIL;
+	}
+
+	data = (zbx_clickhouse_data_t *)zbx_malloc(NULL, sizeof(zbx_clickhouse_data_t));
+	
+	memset(data, 0, sizeof(zbx_clickhouse_data_t));
+	
+	if (NULL != CONFIG_CLICKHOUSE_USERNAME) {
+		//https://clickhouse.yandex/docs/en/interfaces/http/
+		//echo 'SELECT 1' | curl 'http://localhost:8123/?user=user&password=password' -d @-
+		zbx_snprintf_alloc(&data->url,&alloc,&offset,"%s/?user=%s&password=%s",
+			CONFIG_HISTORY_STORAGE_URL, CONFIG_CLICKHOUSE_USERNAME, CONFIG_CLICKHOUSE_PASSWORD);
+	} else {
+		data->url = zbx_strdup(NULL, CONFIG_HISTORY_STORAGE_URL);
+	}
+
+	zbx_rtrim(data->url, "/");
+	data->buf = NULL;
+	hist->value_type = value_type;
+	hist->data = data;
+	hist->destroy = clickhouse_destroy;
+	hist->add_values = clickhouse_add_values;
+	hist->flush = clickhouse_flush;
+	hist->get_values = clickhouse_get_values;
+	hist->requires_trends = 0;
+
+	return SUCCEED;
+}
+
+#else
+
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error)
+{
+	ZBX_UNUSED(hist);
+	ZBX_UNUSED(value_type);
+
+	*error = zbx_strdup(*error, "cURL library support >= 7.28.0 is required for clickhousesearch history backend");
+	return FAIL;
+}
+
+#endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxhistory/history.h glaber/src/libs/zbxhistory/history.h
--- zabbix-4.0.1/src/libs/zbxhistory/history.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxhistory/history.h	2019-05-28 11:38:33.347897745 +0500
@@ -49,4 +49,7 @@
 /* elastic hist */
 int	zbx_history_elastic_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
 
+/* clickhouse hist */
+int	zbx_history_clickhouse_init(zbx_history_iface_t *hist, unsigned char value_type, char **error);
+
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxhistory/Makefile.am glaber/src/libs/zbxhistory/Makefile.am
--- zabbix-4.0.1/src/libs/zbxhistory/Makefile.am	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxhistory/Makefile.am	2019-05-28 11:38:33.347897745 +0500
@@ -5,4 +5,5 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxhistory/Makefile.in glaber/src/libs/zbxhistory/Makefile.in
--- zabbix-4.0.1/src/libs/zbxhistory/Makefile.in	2018-10-29 22:36:11.000000000 +0500
+++ glaber/src/libs/zbxhistory/Makefile.in	2019-05-31 11:29:11.280895355 +0500
@@ -121,7 +121,7 @@
 libzbxhistory_a_AR = $(AR) $(ARFLAGS)
 libzbxhistory_a_LIBADD =
 am_libzbxhistory_a_OBJECTS = history.$(OBJEXT) history_sql.$(OBJEXT) \
-	history_elastic.$(OBJEXT)
+	history_elastic.$(OBJEXT) history_clickhouse.$(OBJEXT) 
 libzbxhistory_a_OBJECTS = $(am_libzbxhistory_a_OBJECTS)
 AM_V_P = $(am__v_P_@AM_V@)
 am__v_P_ = $(am__v_P_@AM_DEFAULT_V@)
@@ -381,7 +381,8 @@
 libzbxhistory_a_SOURCES = \
 	history.c history.h \
 	history_sql.c \
-	history_elastic.c 
+	history_elastic.c \
+	history_clickhouse.c 
 
 all: all-am
 
@@ -434,6 +435,7 @@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_elastic.Po@am__quote@
 @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_sql.Po@am__quote@
+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/history_clickhouse.Po@am__quote@
 
 .c.o:
 @am__fastdepCC_TRUE@	$(AM_V_CC)depbase=`echo $@ | sed 's|[^/]*$$|$(DEPDIR)/&|;s|\.o$$||'`;\
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxicmpping/icmpping.c glaber/src/libs/zbxicmpping/icmpping.c
--- zabbix-4.0.1/src/libs/zbxicmpping/icmpping.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxicmpping/icmpping.c	2019-05-28 11:38:33.347897745 +0500
@@ -24,10 +24,14 @@
 
 extern char	*CONFIG_SOURCE_IP;
 extern char	*CONFIG_FPING_LOCATION;
+extern char	*CONFIG_NMAP_LOCATION;
+extern char	*CONFIG_NMAP_PARAMS;
+
 #ifdef HAVE_IPV6
 extern char	*CONFIG_FPING6_LOCATION;
 #endif
 extern char	*CONFIG_TMPDIR;
+#define MAX_ICMP_NMAP_FIELDS		10
 
 /* old official fping (2.4b2_to_ipv6) did not support source IP address */
 /* old patched versions (2.4b2_to_ipv6) provided either -I or -S options */
@@ -73,6 +77,7 @@
 	*checked = 1;
 }
 
+
 static int	process_ping(ZBX_FPING_HOST *hosts, int hosts_count, int count, int interval, int size, int timeout,
 		char *error, int max_error_len)
 {
@@ -98,7 +103,14 @@
 	assert(hosts);
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() hosts_count:%d", __function_name, hosts_count);
-
+	
+	if (NULL != CONFIG_NMAP_LOCATION && 
+		(-1 == access(CONFIG_NMAP_LOCATION, X_OK) ) ) {
+		//todo: add check of root owner and setuid bit
+		zbx_snprintf(error, max_error_len, "%s: %s", CONFIG_NMAP_LOCATION, zbx_strerror(errno));
+		return ret;
+	}
+	
 	if (-1 == access(CONFIG_FPING_LOCATION, X_OK))
 	{
 #if !defined(HAVE_IPV6)
@@ -242,134 +254,290 @@
 
 	fclose(f);
 
-	zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
-
-	if (NULL == (f = popen(tmp, "r")))
-	{
-		zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
-
-		unlink(filename);
+	//use 1 packet as an indication that we want to use nmap
+	//since it's turned out that doing one packet check via vping is also a good idea, 
+	// timeout =1 (not realistic value ) used to indicate we want nmap to be invoked
+	// this also allows to runtime modification of the utility
+	if ( 1 == count && NULL != CONFIG_NMAP_LOCATION) 
+	{
+		//for 1-packet probes use nmap as accesibility utility
+		//ipv6 ??? i guess it won't work, but who knows: todo: check and fix ipv6 as soon as we have it
+
+		if (-1 == size ) size=32;
+		
+		offset = zbx_snprintf(tmp, sizeof(tmp), "%s -4 --data-length=%d %s -iL %s 2>&1;",
+								CONFIG_NMAP_LOCATION,size,CONFIG_NMAP_PARAMS,filename);
+#ifdef HAVE_IPV6
+		offset = zbx_snprintf(tmp, sizeof(tmp), "%s -6 --data-length=%d %s -iL %s 2>&1",
+								CONFIG_NMAP_LOCATION,size,CONFIG_NMAP_PARAMS,filename);
+#endif
 
-		return ret;
-	}
+		zabbix_log(LOG_LEVEL_DEBUG, "Will run %s", tmp);
 
-	if (NULL == fgets(tmp, sizeof(tmp), f))
-	{
-		strscpy(tmp, "no output");
-	}
-	else
-	{
 		for (i = 0; i < hosts_count; i++)
 		{
-			hosts[i].status = (char *)zbx_malloc(NULL, count);
-			memset(hosts[i].status, 0, count);
+			hosts[i].rcv=0;
+			hosts[i].cnt=count;
 		}
 
+		if ( NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		//	memset(tmp,0,sizeof(char)*
+		if ( NULL == fgets(tmp, sizeof(tmp), f)) {
+			zbx_snprintf(error, max_error_len, "Nmap failed: empty output");
+			return ret;
+		}
+		
 		do
 		{
+			char *fields[MAX_ICMP_NMAP_FIELDS];
+			char *end_field;
+			char *latency;
+
 			zbx_rtrim(tmp, "\n");
 			zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
 
+			if (25 > strnlen(tmp,MAX_STRING_LEN) ) {
+				zabbix_log(LOG_LEVEL_DEBUG, "skipping too short line");
+				continue;
+			} 
+
+			//splitting line into fields
+			char *field_ptr = strtok_r(tmp, " ", &end_field);
+			int field_count=0;
+
+			for (i=0; i++; i<field_count) 
+				fields[i]=NULL; 
+
+			while ( field_ptr != NULL && MAX_ICMP_NMAP_FIELDS > field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "read field %d [%s]",field_count, field_ptr);
+			    fields[field_count++]=field_ptr;
+			    field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if ( NULL == fields[4]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String 1 has not enough fields ");
+				continue;
+			}
+			
+			if (strcmp("Nmap",fields[0]) != 0 ||
+				strcmp("scan",fields[1]) !=0  ||
+				strcmp("report", fields[2]) !=0 )  
+			{  
+				zabbix_log(LOG_LEVEL_DEBUG, "String doesn't match 'Nmap scan for', skipping");
+				continue;
+			}
+
 			host = NULL;
 
-			if (NULL != (c = strchr(tmp, ' ')))
+			for (i = 0; i < hosts_count; i++)
 			{
-				*c = '\0';
-				for (i = 0; i < hosts_count; i++)
-					if (0 == strcmp(tmp, hosts[i].addr))
-					{
-						host = &hosts[i];
-						break;
-					}
-				*c = ' ';
+				if (0 == strcmp(fields[4], hosts[i].addr))
+				{
+					host = &hosts[i];
+					zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+					break;
+				}
 			}
 
-			if (NULL == host)
+			if (NULL == host) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host hasn't been found in the request");
 				continue;
+			} else {
+				zabbix_log(LOG_LEVEL_DEBUG, "Host has been found %s", fields[4]);
+			}
 
-			if (NULL == (c = strstr(tmp, " : ")))
+			if (NULL == fgets(tmp, sizeof(tmp), f)) {
+				zabbix_log(LOG_LEVEL_DEBUG, "Couldn't read second line");
 				continue;
+			}
 
-			/* when NIC bonding is used, there are also lines like */
-			/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+			zabbix_log(LOG_LEVEL_DEBUG, "read line %s", tmp);
+			zbx_rtrim(tmp, "\n");
 
-			if (NULL != strstr(tmp, "duplicate for"))
-				continue;
+			field_ptr = strtok_r(tmp, " ", &end_field);
 
-			c += 3;
+			for (i = 0; i++; i<field_count)
+				fields[i]=NULL;
 
-			/* The were two issues with processing only the fping's final status line:  */
-			/*   1) pinging broadcast addresses could have resulted in responses from   */
-			/*      different hosts, which were counted as the target host responses;   */
-			/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
-			/*      address will result in no individual responses, but the final       */
-			/*      status line might contain a bogus value.                            */
-			/* Because of the above issues we must monitor the individual responses     */
-			/* and mark the valid ones.                                                 */
-			if ('[' == *c)
+			field_count=0;
+
+			while (field_ptr != NULL && MAX_ICMP_NMAP_FIELDS>field_count) 
+			{	
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 parced field %s",field_ptr);
+				fields[field_count++]=field_ptr;
+				field_ptr = strtok_r(NULL, " ", &end_field);
+			}
+
+			if (NULL == fields[3]) {
+				zabbix_log(LOG_LEVEL_DEBUG, "String too short");
+				continue;
+			}
+
+			if ( 0 != strncmp(fields[0], "Host", 2) ||
+				 0 != strncmp(fields[1], "is", 2)  ||
+				 0 != strncmp(fields[2], "up", 2) ) 
 			{
-				/* Fping appends response source address in format '[<- 10.3.0.10]' */
-				/* if it does not match the target address. Ignore such responses.  */
-				if (NULL != strstr(c + 1, "[<-"))
-					continue;
+				zabbix_log(LOG_LEVEL_DEBUG, "String 2 doesn't match 'Host is up', skipping");
+				continue;
+			}
 
-				/* get the index of individual ping response */
-				index = atoi(c + 1);
+			latency=fields[3]+1;
+			zbx_rtrim(latency,"s");
+			sec=atof(latency);
+
+			host->rcv=count;
+			host->min=sec;
+			host->max=sec;
+			host->sum=sec*count;
 
-				if (0 > index || index >= count)
-					continue;
+			zabbix_log(LOG_LEVEL_DEBUG, "Final parced info is host=%s , latency=%f",host->addr,sec);
 
-				host->status[index] = 1;
+			ret = SUCCEED;
+		}
+		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-				continue;
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "Nmap failed");
+
+	} else 
+	{
+		//doing things fping way
+		zabbix_log(LOG_LEVEL_DEBUG, "%s", tmp);
+
+		if (NULL == (f = popen(tmp, "r")))
+		{
+			zbx_snprintf(error, max_error_len, "%s: %s", tmp, zbx_strerror(errno));
+			unlink(filename);
+			return ret;
+		}
+
+		if (NULL == fgets(tmp, sizeof(tmp), f))
+		{
+			strscpy(tmp, "no output");
+		}
+		else
+		{
+			for (i = 0; i < hosts_count; i++)
+			{
+				hosts[i].status = (char *)zbx_malloc(NULL, count);
+				memset(hosts[i].status, 0, count);
 			}
 
-			/* process status line for a host */
-			index = 0;
 			do
 			{
-				if (1 == host->status[index])
+				zbx_rtrim(tmp, "\n");
+				zabbix_log(LOG_LEVEL_DEBUG, "read line [%s]", tmp);
+
+				host = NULL;
+
+				if (NULL != (c = strchr(tmp, ' ')))
 				{
-					sec = atof(c) / 1000; /* convert ms to seconds */
+					*c = '\0';
+					for (i = 0; i < hosts_count; i++)
+						if (0 == strcmp(tmp, hosts[i].addr))
+						{
+							host = &hosts[i];
+							break;
+						}
+					*c = ' ';
+				}
+
+				if (NULL == host)
+					continue;
+
+				if (NULL == (c = strstr(tmp, " : ")))
+					continue;
+
+				/* when NIC bonding is used, there are also lines like */
+				/* 192.168.1.2 : duplicate for [0], 96 bytes, 0.19 ms */
+
+				if (NULL != strstr(tmp, "duplicate for"))
+					continue;
+
+				c += 3;
 
-					if (0 == host->rcv || host->min > sec)
-						host->min = sec;
-					if (0 == host->rcv || host->max < sec)
-						host->max = sec;
-					host->sum += sec;
-					host->rcv++;
+				/* The were two issues with processing only the fping's final status line:  */
+				/*   1) pinging broadcast addresses could have resulted in responses from   */
+				/*      different hosts, which were counted as the target host responses;   */
+				/*   2) there is a bug in fping (v3.8 at least) where pinging broadcast     */
+				/*      address will result in no individual responses, but the final       */
+				/*      status line might contain a bogus value.                            */
+				/* Because of the above issues we must monitor the individual responses     */
+				/* and mark the valid ones.                                                 */
+				if ('[' == *c)
+				{
+					/* Fping appends response source address in format '[<- 10.3.0.10]' */
+					/* if it does not match the target address. Ignore such responses.  */
+					if (NULL != strstr(c + 1, "[<-"))
+						continue;
+
+					/* get the index of individual ping response */
+					index = atoi(c + 1);
+
+					if (0 > index || index >= count)
+						continue;
+
+					host->status[index] = 1;
+
+					continue;
 				}
-			}
-			while (++index < count && NULL != (c = strchr(c + 1, ' ')));
 
-			host->cnt += count;
+				/* process status line for a host */
+				index = 0;
+				do
+				{
+					if (1 == host->status[index])
+					{
+						sec = atof(c) / 1000; /* convert ms to seconds */
+
+						if (0 == host->rcv || host->min > sec)
+							host->min = sec;
+						if (0 == host->rcv || host->max < sec)
+							host->max = sec;
+						host->sum += sec;
+						host->rcv++;
+					}
+				}
+				while (++index < count && NULL != (c = strchr(c + 1, ' ')));
+
+				host->cnt += count;
 #ifdef HAVE_IPV6
-			if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
-					0 != (fping_existence & FPING_EXISTS) &&
-					0 != (fping_existence & FPING6_EXISTS))
-			{
-				memset(host->status, 0, count);	/* reset response statuses for IPv6 */
-			}
+				if (host->cnt == count && NULL == CONFIG_SOURCE_IP &&
+						0 != (fping_existence & FPING_EXISTS) &&
+						0 != (fping_existence & FPING6_EXISTS))
+				{
+					memset(host->status, 0, count);	/* reset response statuses for IPv6 */
+				}
 #endif
-			ret = SUCCEED;
+				ret = SUCCEED;
+			}
+			while (NULL != fgets(tmp, sizeof(tmp), f));
+
+			for (i = 0; i < hosts_count; i++)
+				zbx_free(hosts[i].status);
 		}
-		while (NULL != fgets(tmp, sizeof(tmp), f));
 
-		for (i = 0; i < hosts_count; i++)
-			zbx_free(hosts[i].status);
+		if (NOTSUPPORTED == ret)
+			zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 	}
-	pclose(f);
 
+	pclose(f);
 	unlink(filename);
 
-	if (NOTSUPPORTED == ret)
-		zbx_snprintf(error, max_error_len, "fping failed: %s", tmp);
 
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
 
 	return ret;
 }
 
+
 /******************************************************************************
  *                                                                            *
  * Function: do_ping                                                          *
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxmedia/email.c glaber/src/libs/zbxmedia/email.c
--- zabbix-4.0.1/src/libs/zbxmedia/email.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxmedia/email.c	2019-05-28 11:38:33.347897745 +0500
@@ -32,6 +32,7 @@
 
 /* multiple 'encoded-word's should be separated by <CR><LF><SPACE> */
 #define ZBX_EMAIL_ENCODED_WORD_SEPARATOR	"\r\n "
+extern int CONFIG_TIMEOUT; 
 
 /******************************************************************************
  *                                                                            *
@@ -425,7 +426,7 @@
 
 	/* connect to and receive an initial greeting from SMTP server */
 
-	if (FAIL == zbx_tcp_connect(&s, CONFIG_SOURCE_IP, smtp_server, smtp_port, 0, ZBX_TCP_SEC_UNENCRYPTED, NULL,
+	if (FAIL == zbx_tcp_connect(&s, CONFIG_SOURCE_IP, smtp_server, smtp_port, CONFIG_TIMEOUT, ZBX_TCP_SEC_UNENCRYPTED, NULL,
 			NULL))
 	{
 		zbx_snprintf(error, max_error_len, "cannot connect to SMTP server \"%s\": %s",
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxself/selfmon.c glaber/src/libs/zbxself/selfmon.c
--- zabbix-4.0.1/src/libs/zbxself/selfmon.c	2018-10-29 22:36:01.000000000 +0500
+++ glaber/src/libs/zbxself/selfmon.c	2019-05-28 11:38:33.351897831 +0500
@@ -89,6 +89,8 @@
 extern char	*CONFIG_FILE;
 extern int	CONFIG_POLLER_FORKS;
 extern int	CONFIG_UNREACHABLE_POLLER_FORKS;
+extern int	CONFIG_ASYNC_SNMP_POLLER_FORKS;
+extern int	CONFIG_ASYNC_AGENT_POLLER_FORKS;
 extern int	CONFIG_IPMIPOLLER_FORKS;
 extern int	CONFIG_PINGER_FORKS;
 extern int	CONFIG_JAVAPOLLER_FORKS;
@@ -138,6 +140,10 @@
 	{
 		case ZBX_PROCESS_TYPE_POLLER:
 			return CONFIG_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+			return CONFIG_ASYNC_AGENT_POLLER_FORKS;
+		case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+			return CONFIG_ASYNC_SNMP_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_UNREACHABLE:
 			return CONFIG_UNREACHABLE_POLLER_FORKS;
 		case ZBX_PROCESS_TYPE_IPMIPOLLER:
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/libs/zbxserver/expression.c glaber/src/libs/zbxserver/expression.c
--- zabbix-4.0.1/src/libs/zbxserver/expression.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/libs/zbxserver/expression.c	2019-05-28 11:38:33.351897831 +0500
@@ -3758,6 +3758,11 @@
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
 							ZBX_REQUEST_HOST_DNS);
 				}
+				else if (0 == strcmp(m, MVAR_HOST_DESCRIPTION))
+				{
+					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
+							ZBX_REQUEST_HOST_DESCRIPTION);
+				}
 				else if (0 == strcmp(m, MVAR_HOST_CONN))
 				{
 					ret = DBget_trigger_value(event->trigger.expression, &replace_to, N_functionid,
@@ -4660,7 +4665,7 @@
 	zbx_hashset_iter_t	iter;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() funcs_num:%d", __function_name, funcs->num_data);
-
+	
 	zbx_vector_uint64_create(&itemids);
 	zbx_vector_uint64_reserve(&itemids, funcs->num_data);
 
@@ -4675,7 +4680,6 @@
 	errcodes = (int *)zbx_malloc(errcodes, sizeof(int) * (size_t)itemids.values_num);
 
 	DCconfig_get_items_by_itemids(items, itemids.values, errcodes, itemids.values_num);
-
 	zbx_hashset_iter_reset(funcs, &iter);
 	while (NULL != (func = (zbx_func_t *)zbx_hashset_iter_next(&iter)))
 	{
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_proxy/proxy.c glaber/src/zabbix_proxy/proxy.c
--- zabbix-4.0.1/src/zabbix_proxy/proxy.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_proxy/proxy.c	2019-05-28 11:38:33.371898260 +0500
@@ -144,6 +144,7 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_POLLER_FORKS	= 2;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TRAPPER_FORKS		= 5;
@@ -262,6 +263,13 @@
 
 char	*CONFIG_HISTORY_STORAGE_URL		= NULL;
 char	*CONFIG_HISTORY_STORAGE_OPTS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME		= NULL;
+
+
+char *CONFIG_NMAP_PARAMS = NULL;
+char *CONFIG_NMAP_LOCATION = NULL;
+
 int	CONFIG_HISTORY_STORAGE_PIPELINES	= 0;
 
 int	get_process_info_by_thread(int local_server_num, unsigned char *local_process_type, int *local_process_num);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/events.c glaber/src/zabbix_server/events.c
--- zabbix-4.0.1/src/zabbix_server/events.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/events.c	2019-05-28 11:38:33.375898346 +0500
@@ -1713,10 +1713,12 @@
 			zbx_json_close(&json);
 		}
 
-		zbx_hashset_clear(&hosts);
+			zbx_hashset_clear(&hosts);
 		zbx_vector_uint64_clear(&hostids);
 
-		zbx_problems_export_write(json.buffer, json.buffer_size);
+		if (SUCCEED == zbx_is_export_enabled())
+			zbx_problems_export_write(json.buffer, json.buffer_size);
+
 	}
 
 	zbx_hashset_iter_reset(&event_recovery, &iter);
@@ -1734,8 +1736,10 @@
 		zbx_json_addint64(&json, ZBX_PROTO_TAG_VALUE, event->value);
 		zbx_json_adduint64(&json, ZBX_PROTO_TAG_EVENTID, event->eventid);
 		zbx_json_adduint64(&json, ZBX_PROTO_TAG_PROBLEM_EVENTID, recovery->eventid);
-
-		zbx_problems_export_write(json.buffer, json.buffer_size);
+		
+		if (SUCCEED == zbx_is_export_enabled())
+			zbx_problems_export_write(json.buffer, json.buffer_size);
+	
 	}
 
 	zbx_problems_export_flush();
@@ -2563,8 +2567,11 @@
 		DCconfig_triggers_apply_changes(&trigger_diff);
 		DBupdate_itservices(&trigger_diff);
 
-		if (SUCCEED == zbx_is_export_enabled())
-			zbx_export_events();
+		//export is used to keep problems hash in memory, but data is flushed to dissk only if export is enabled
+		//inside zbx_export_events() 
+		
+		//if (SUCCEED == zbx_is_export_enabled())
+		zbx_export_events();
 
 		zbx_clean_events();
 		zbx_vector_ptr_clear_ext(&trigger_diff, (zbx_clean_func_t)zbx_trigger_diff_free);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/pinger/pinger.c glaber/src/zabbix_server/pinger/pinger.c
--- zabbix-4.0.1/src/zabbix_server/pinger/pinger.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/pinger/pinger.c	2019-05-28 11:38:33.379898432 +0500
@@ -411,13 +411,20 @@
 static void	get_pinger_hosts(icmpitem_t **icmp_items, int *icmp_items_alloc, int *icmp_items_count)
 {
 	const char		*__function_name = "get_pinger_hosts";
-	DC_ITEM			items[MAX_PINGER_ITEMS];
+	DC_ITEM			*items;
 	int			i, num, count, interval, size, timeout, rc, errcode = SUCCEED;
 	char			error[MAX_STRING_LEN], *addr = NULL;
 	icmpping_t		icmpping;
 	icmppingsec_type_t	type;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
+	
+
+	if (NULL == (items=zbx_malloc(NULL,sizeof(DC_ITEM)*MAX_PINGER_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for pinger items");
+		return;
+	}
 
 	num = DCconfig_get_poller_items(ZBX_POLLER_TYPE_PINGER, items);
 
@@ -455,9 +462,8 @@
 	}
 
 	DCconfig_clean_items(items, NULL, num);
-
+	zbx_free(items);
 	zbx_preprocessor_flush();
-
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, *icmp_items_count);
 }
 
@@ -540,7 +546,8 @@
 		if (i == items_count - 1 || items[i].count != items[i + 1].count || items[i].interval != items[i + 1].interval ||
 				items[i].size != items[i + 1].size || items[i].timeout != items[i + 1].timeout)
 		{
-			zbx_setproctitle("%s #%d [pinging hosts]", get_process_type_string(process_type), process_num);
+			//that useless as most of the time process status is "pinging hosts"
+			//zbx_setproctitle("%s #%d [pinging hosts]", get_process_type_string(process_type), process_num);
 
 			zbx_timespec(&ts);
 
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/poller/checks_agent.c glaber/src/zabbix_server/poller/checks_agent.c
--- zabbix-4.0.1/src/zabbix_server/poller/checks_agent.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/poller/checks_agent.c	2019-05-31 11:29:11.284895441 +0500
@@ -94,7 +94,7 @@
 			goto out;
 	}
 
-	if (SUCCEED == (ret = zbx_tcp_connect(&s, CONFIG_SOURCE_IP, item->interface.addr, item->interface.port, 0,
+	if (SUCCEED == (ret = zbx_tcp_connect(&s, CONFIG_SOURCE_IP, item->interface.addr, item->interface.port, CONFIG_TIMEOUT,
 			item->host.tls_connect, tls_arg1, tls_arg2)))
 	{
 		zabbix_log(LOG_LEVEL_DEBUG, "Sending [%s]", item->key);
@@ -152,3 +152,257 @@
 
 	return ret;
 }
+
+
+#define SKIPPED			11
+#define SOCKET_CREATED	12
+#define CONNECT_SENT	13
+#define REQ_SENT		14
+#define	CLOSED			15
+//#define ZBX_AGENT_MAX_RESPONSE_TIME 2
+
+//this function follows the socket status and 
+//handles operations according to the socket state
+void handle_socket_operation(zbx_socket_t *socket, DC_ITEM * item, int *errcode, int *conn_status, 
+						 AGENT_RESULT *result, int *active_agents) 
+{
+	
+	ZBX_SOCKADDR	servaddr_in;
+	struct hostent	*hp;
+	ssize_t		received_len;
+	
+	int status;
+
+	switch (*conn_status) {
+		
+		case CONNECT_SENT:
+			zabbix_log(LOG_LEVEL_DEBUG,"Sending data to the socket");
+
+			if (SUCCEED != zbx_tcp_send(socket, item->key))
+			{
+				*errcode = NETWORK_ERROR;
+				*conn_status = FAIL;
+				SET_MSG_RESULT(result, zbx_strdup(NULL, "Cannot send request to the agent"));
+				zabbix_log(LOG_LEVEL_DEBUG,"Data send fail, aborting session");
+			} else  *conn_status=REQ_SENT;
+			break;
+
+		case REQ_SENT:
+			if (FAIL != (received_len = zbx_tcp_recv_ext(socket, 0)))
+			{
+				*errcode = SUCCEED;
+				zabbix_log(LOG_LEVEL_DEBUG, "get value from agent result: '%s'", socket->buffer);
+
+				zbx_rtrim(socket->buffer, " \r\n");
+				zbx_ltrim(socket->buffer, " ");
+
+				if (0 == strcmp(socket->buffer, ZBX_NOTSUPPORTED))
+				{
+					/* 'ZBX_NOTSUPPORTED\0<error message>' */
+					if (sizeof(ZBX_NOTSUPPORTED) < socket->read_bytes)
+						SET_MSG_RESULT(result, zbx_dsprintf(NULL, "%s", socket->buffer + sizeof(ZBX_NOTSUPPORTED)));
+					else
+						SET_MSG_RESULT(result, zbx_strdup(NULL, "Not supported by Zabbix Agent"));
+						*errcode = NOTSUPPORTED;
+				}
+				else if (0 == strcmp(socket->buffer, ZBX_ERROR))
+				{
+					SET_MSG_RESULT(result, zbx_strdup(NULL, "Zabbix Agent non-critical error"));
+					*errcode = AGENT_ERROR;
+				}
+				else if (0 == received_len)
+				{
+					SET_MSG_RESULT(result, zbx_dsprintf(NULL, "Received empty response from Zabbix Agent at [%s]."
+						" Assuming that agent dropped connection because of access permissions.", item->interface.addr));
+					*errcode = NETWORK_ERROR;
+				}
+				else
+					set_result_type(result, ITEM_VALUE_TYPE_TEXT, socket->buffer);
+			} else 
+			{
+					zabbix_log(LOG_LEVEL_DEBUG, "Get value from agent failed: %s", zbx_socket_strerror());
+					SET_MSG_RESULT(result, zbx_dsprintf(NULL, "Get value from agent failed: %s", zbx_socket_strerror()));
+					*errcode=NETWORK_ERROR;
+			}					
+		
+			zbx_tcp_close(socket);				
+			socket->socket=0;
+			*conn_status=CLOSED;
+			
+			*active_agents=*active_agents-1;
+			
+			zabbix_log(LOG_LEVEL_DEBUG, "finished socket processing %d",*active_agents);
+			break;
+	} 
+
+}
+
+
+int	get_value_agent_async(DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num)
+{
+	const char	*__function_name = "get_value_agent_async";
+	zbx_socket_t	*s;	
+	char		*tls_arg1, *tls_arg2;
+	int			i,	ret=SUCCEED,	max_socket, processed_vals=1;
+	// connects=0;
+	int 		*conn_status;
+	unsigned int active_agents=0;
+	unsigned int starttime;
+
+
+	zabbix_log(LOG_LEVEL_DEBUG,"Started async agent polling for %d items", num);
+
+	if (NULL == (s=zbx_malloc(NULL, num*sizeof(zbx_socket_t)))) {
+		zabbix_log(LOG_LEVEL_WARNING,"Couldn't allocate memory for sockets");
+		return FAIL;
+	};
+
+	memset(s, 0, num*sizeof(zbx_socket_t));
+	
+	if (NULL == (conn_status=zbx_malloc(NULL, num*sizeof(unsigned int))))
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Couldn't allocate memory for sockets");
+		return FAIL;
+	};
+	
+	
+	//starting connections
+	for ( i = 0; i < num; i++ ) 
+	{
+		s[i].buf_type = ZBX_BUF_TYPE_STAT;
+		s[i].buffer=s[i].buf_stat;
+
+		//cheick if the item is agent type
+		if (  ITEM_TYPE_ZABBIX != items[i].type )	
+		{	
+			conn_status[i]=SKIPPED;
+			continue;
+		}
+			
+		zabbix_log(LOG_LEVEL_TRACE, "In %s() host:'%s' addr:'%s' key:'%s' conn:'%s'", __function_name,
+				items[i].host.host, items[i].interface.addr, items[i].key,
+				zbx_tcp_connection_type_name(items[i].host.tls_connect));
+
+		switch (items[i].host.tls_connect)
+		{
+			case ZBX_TCP_SEC_UNENCRYPTED:
+				tls_arg1 = NULL;
+				tls_arg2 = NULL;
+				break;
+#if defined(HAVE_POLARSSL) || defined(HAVE_GNUTLS) || defined(HAVE_OPENSSL)
+			case ZBX_TCP_SEC_TLS_CERT:
+				tls_arg1 = item->host.tls_issuer;
+				tls_arg2 = item->host.tls_subject;
+				break;
+			case ZBX_TCP_SEC_TLS_PSK:
+				tls_arg1 = items[i].host.tls_psk_identity;
+				tls_arg2 = items[i].host.tls_psk;
+				break;
+#else
+			case ZBX_TCP_SEC_TLS_CERT:
+			case ZBX_TCP_SEC_TLS_PSK:
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "A TLS connection is configured to be used with agent"
+					" but support for TLS was not compiled into %s.",
+					get_program_type_string(program_type)));
+				conn_status[i]=SKIPPED;
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+#endif
+			default:
+				THIS_SHOULD_NEVER_HAPPEN;
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Invalid TLS connection parameters."));
+				conn_status[i]=SKIPPED;
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+	
+		}
+
+		if (SUCCEED != (ret = zbx_tcp_connect(&s[i], CONFIG_SOURCE_IP, items[i].interface.addr, items[i].interface.port, 0,
+			items[i].host.tls_connect, tls_arg1, tls_arg2))) {
+
+			conn_status[i]=SKIPPED;
+			errcodes[i]=NETWORK_ERROR;
+			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Couldn't create socket"));
+			continue;
+		}
+
+		conn_status[i]=CONNECT_SENT;
+		max_socket=s[i].socket;
+		active_agents++;
+		
+		
+	}
+			
+	starttime=time(NULL);
+	zabbix_log(LOG_LEVEL_DEBUG,"Starting waiting for %d sockets to connect",active_agents);
+
+	while (active_agents>0 && (time(NULL)-starttime)< CONFIG_TIMEOUT && processed_vals>0)
+	{
+		
+		//this was the simplest and compact way to implement async io
+		//i has tried select() + FD_ISSET, while its seems to work
+		//it requires much more CPU for large batches of hosts
+		//probably it's worth of trying libevent if some problems arise, especially it's already 
+		//used and linked to the daemon, but one usleep hanles all that 
+		
+		usleep(10000);
+		
+		for ( i=0; i<num; i++) 
+		{
+			if (CONNECT_SENT != conn_status[i] && REQ_SENT != conn_status[i] )
+				continue;
+
+			//the socket is in connection phase, checking that it's ready to be written to
+			if (CONNECT_SENT == conn_status[i]) {
+				int result,ret;
+				socklen_t result_len = sizeof(result);
+				
+				ret=getsockopt(s[i].socket, SOL_SOCKET, SO_ERROR, &result, &result_len); 
+				if (ret<0)
+				{
+    				zabbix_log(LOG_LEVEL_DEBUG, "Connection is not ready yet %d", ret);
+    				continue;
+				}
+				if ( 0!= result ) {
+					zabbix_log(LOG_LEVEL_DEBUG, "Connection %d has failed", i);
+					if (NULL == &results[i]) SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Connection to the host failed: check firewall rules and agent is running"));
+					conn_status[i]==CLOSED;
+					errcodes[i]=NETWORK_ERROR;
+					continue;
+				}
+				processed_vals++;
+
+			} else 	if (REQ_SENT == conn_status[i] ) 
+			{ 
+				//checking if there are some data waiting for us in the socket
+				int count;
+				ioctl(s[i].socket, FIONREAD, &count);
+			
+				if ( 0 == count) continue;  
+				processed_vals++;
+			} 
+			handle_socket_operation(&s[i],&items[i],&errcodes[i],&conn_status[i],&results[i],&active_agents);
+		}
+		
+	} 
+	
+	zabbix_log(LOG_LEVEL_DEBUG,"There are %d active connections timed-out",active_agents); 
+
+	//closing sockets for timed out items
+	for ( i = 0; i < num; i++) 
+	{
+		if (s[i].socket) zbx_tcp_close(&s[i]);
+
+		if (REQ_SENT == conn_status[i] || CONNECT_SENT ==conn_status[i]) {
+			zabbix_log(LOG_LEVEL_DEBUG, "Connection %d has timed out while waiting for responce", num);
+//			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Waiting for responce timed out"));
+			errcodes[i]=TIMEOUT_ERROR;
+			continue;
+		}
+	}
+
+	zbx_free(s);
+	zbx_free(conn_status);
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s: %d agents, %d succesifull",__function_name, num, num-active_agents);
+}
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/poller/checks_agent.h glaber/src/zabbix_server/poller/checks_agent.h
--- zabbix-4.0.1/src/zabbix_server/poller/checks_agent.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/poller/checks_agent.h	2019-05-28 11:38:33.379898432 +0500
@@ -27,4 +27,8 @@
 
 int	get_value_agent(DC_ITEM *item, AGENT_RESULT *result);
 
+//this is coming soon 
+int	get_value_agent_async(DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
+
+
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.c glaber/src/zabbix_server/poller/checks_snmp.c
--- zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/poller/checks_snmp.c	2019-05-28 11:38:33.383898517 +0500
@@ -24,6 +24,7 @@
 #define SNMP_NO_DEBUGGING		/* disabling debugging messages from Net-SNMP library */
 #include <net-snmp/net-snmp-config.h>
 #include <net-snmp/net-snmp-includes.h>
+#include <net-snmp/library/large_fd_set.h>
 
 #include "comms.h"
 #include "zbxalgo.h"
@@ -1548,14 +1549,23 @@
 	static zbx_mib_norm_t mibs[] =
 	{
 		/* the most popular items first */
+		{LEN_STR("ifHCOutUcastPkts"),".1.3.6.1.2.1.31.1.1.1.11"},
+		{LEN_STR("ifHCInUcastPkts"),".1.3.6.1.2.1.31.1.1.1.7"},
+		{LEN_STR("ifHCInOctets"),	".1.3.6.1.2.1.31.1.1.1.6"},
+		{LEN_STR("ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("rmon.19.2.0"),	".1.3.6.1.2.1.16.19.2.0"},
+		{LEN_STR("ifHighSpeed"),	".1.3.6.1.2.1.31.1.1.1.15"},
+ 		{LEN_STR("ifAlias"),		".1.3.6.1.2.1.31.1.1.1.18"},
 		{LEN_STR("ifDescr"),		".1.3.6.1.2.1.2.2.1.2"},
 		{LEN_STR("ifInOctets"),		".1.3.6.1.2.1.2.2.1.10"},
 		{LEN_STR("ifOutOctets"),	".1.3.6.1.2.1.2.2.1.16"},
+		{LEN_STR("sysName"),		".1.3.6.1.2.1.1.5"},
 		{LEN_STR("ifAdminStatus"),	".1.3.6.1.2.1.2.2.1.7"},
 		{LEN_STR("ifOperStatus"),	".1.3.6.1.2.1.2.2.1.8"},
 		{LEN_STR("ifIndex"),		".1.3.6.1.2.1.2.2.1.1"},
-		{LEN_STR("ifType"),		".1.3.6.1.2.1.2.2.1.3"},
-		{LEN_STR("ifMtu"),		".1.3.6.1.2.1.2.2.1.4"},
+		{LEN_STR("ifType"),		    ".1.3.6.1.2.1.2.2.1.3"},
+		{LEN_STR("ifMtu"),	  	    ".1.3.6.1.2.1.2.2.1.4"},
 		{LEN_STR("ifSpeed"),		".1.3.6.1.2.1.2.2.1.5"},
 		{LEN_STR("ifPhysAddress"),	".1.3.6.1.2.1.2.2.1.6"},
 		{LEN_STR("ifInUcastPkts"),	".1.3.6.1.2.1.2.2.1.11"},
@@ -1568,6 +1578,10 @@
 		{LEN_STR("ifOutDiscards"),	".1.3.6.1.2.1.2.2.1.19"},
 		{LEN_STR("ifOutErrors"),	".1.3.6.1.2.1.2.2.1.20"},
 		{LEN_STR("ifOutQLen"),		".1.3.6.1.2.1.2.2.1.21"},
+		{LEN_STR("IF-MIB::ifHCOutOctets"),	".1.3.6.1.2.1.31.1.1.1.10"},
+		{LEN_STR("IF-MIB::ifHCInOctets"),	".1.3.6.1.2.1.31.1.1.1.6"},
+		{LEN_STR("IF-MIB::ifOutUcastPkts"),	".1.3.6.1.2.1.2.2.1.17"},
+		{LEN_STR("IF-MIB::ifInUcastPkts"),	".1.3.6.1.2.1.2.2.1.11"},
 		{0}
 	};
 #undef LEN_STR
@@ -2083,46 +2097,38 @@
 
 	struct snmp_session	*ss;
 	char			error[MAX_STRING_LEN];
-	int			i, j, err = SUCCEED, max_succeed = 0, min_fail = MAX_SNMP_ITEMS + 1,
+	int			i,  err = SUCCEED, max_succeed = 0, min_fail = MAX_SNMP_ITEMS + 1,
 				bulk = SNMP_BULK_ENABLED;
 
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s() host:'%s' addr:'%s' num:%d",
 			__function_name, items[0].host.host, items[0].interface.addr, num);
+	
 
-	for (j = 0; j < num; j++)	/* locate first supported item to use as a reference */
-	{
-		if (SUCCEED == errcodes[j])
-			break;
-	}
-
-	if (j == num)	/* all items already NOTSUPPORTED (with invalid key, port or SNMP parameters) */
-		goto out;
-
-	if (NULL == (ss = zbx_snmp_open_session(&items[j], error, sizeof(error))))
+	if (NULL == (ss = zbx_snmp_open_session(&items[0], error, sizeof(error))))
 	{
 		err = NETWORK_ERROR;
 		goto exit;
 	}
 
-	if (0 != (ZBX_FLAG_DISCOVERY_RULE & items[j].flags) || 0 == strncmp(items[j].snmp_oid, "discovery[", 10))
+	if (0 != (ZBX_FLAG_DISCOVERY_RULE & items[0].flags) || 0 == strncmp(items[0].snmp_oid, "discovery[", 10))
 	{
 		int	max_vars;
 
-		max_vars = DCconfig_get_suggested_snmp_vars(items[j].interface.interfaceid, &bulk);
+		max_vars = DCconfig_get_suggested_snmp_vars(items[0].interface.interfaceid, &bulk);
 
-		err = zbx_snmp_process_discovery(ss, &items[j], &results[j], &errcodes[j], error, sizeof(error),
+		err = zbx_snmp_process_discovery(ss, &items[0], &results[0], &errcodes[0], error, sizeof(error),
 				&max_succeed, &min_fail, max_vars, bulk);
 	}
-	else if (NULL != strchr(items[j].snmp_oid, '['))
+	else if (NULL != strchr(items[0].snmp_oid, '['))
 	{
-		(void)DCconfig_get_suggested_snmp_vars(items[j].interface.interfaceid, &bulk);
+		(void)DCconfig_get_suggested_snmp_vars(items[0].interface.interfaceid, &bulk);
 
-		err = zbx_snmp_process_dynamic(ss, items + j, results + j, errcodes + j, num - j, error, sizeof(error),
+		err = zbx_snmp_process_dynamic(ss, items, results, errcodes, num , error, sizeof(error),
 				&max_succeed, &min_fail, bulk);
 	}
 	else
 	{
-		err = zbx_snmp_process_standard(ss, items + j, results + j, errcodes + j, num - j, error, sizeof(error),
+		err = zbx_snmp_process_standard(ss, items, results, errcodes, num , error, sizeof(error),
 				&max_succeed, &min_fail);
 	}
 
@@ -2131,19 +2137,12 @@
 	if (SUCCEED != err)
 	{
 		zabbix_log(LOG_LEVEL_DEBUG, "getting SNMP values failed: %s", error);
-
-		for (i = j; i < num; i++)
-		{
-			if (SUCCEED != errcodes[i])
-				continue;
-
-			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, error));
-			errcodes[i] = err;
-		}
+		SET_MSG_RESULT(&results[0], zbx_strdup(NULL, error));
+		errcodes[0] = err;
 	}
 	else if (SNMP_BULK_ENABLED == bulk && (0 != max_succeed || MAX_SNMP_ITEMS + 1 != min_fail))
 	{
-		DCconfig_update_interface_snmp_stats(items[j].interface.interfaceid, max_succeed, min_fail);
+		DCconfig_update_interface_snmp_stats(items[0].interface.interfaceid, max_succeed, min_fail);
 	}
 out:
 	zabbix_log(LOG_LEVEL_DEBUG, "End of %s()", __function_name);
@@ -2154,4 +2153,424 @@
 	init_snmp(progname);
 }
 
+
+
+//to do: consider giving up this function, it's pretty useless, could be replaced by one if statement
+int async_submit_result (int status, struct snmp_session *sp, struct snmp_pdu *response, AGENT_RESULT *result)
+{
+	const char	*__function_name = "async_submit_result";
+	struct variable_list *var;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In: %s() started ",__function_name);
+
+
+	switch (status) 
+	{
+		case STAT_SUCCESS:
+			var = response->variables;
+		 	zabbix_log(LOG_LEVEL_DEBUG, "In: %s() stat_success %ld",__function_name,response->errstat);
+
+			if (SNMP_ERR_NOERROR == response->errstat) 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "In: %s() before while ",__function_name);
+				while (var) 
+				{
+					zabbix_log(LOG_LEVEL_DEBUG, "%s() calling zbx_snmp_set_result ",__function_name);
+					zbx_snmp_set_result(var, result);
+					var = var->next_variable;
+				}
+			} else 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was an error in SNMP responce from the host",__function_name);
+			}
+			return SUCCEED;
+
+			case STAT_TIMEOUT:
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was a timeout in SNMP request to %s",__function_name,sp->peername);
+				return FAIL;
+
+			case STAT_ERROR:
+				zabbix_log(LOG_LEVEL_DEBUG, "%s() there was an error in SNMP responce from %s",__function_name,sp->peername);
+				return 0;
+	}
+	return 0;
+}
+
+/* structures keep thread safe per session configuration to be used in snmp callbacks */
+struct async_snmp_conf
+{
+	size_t	parsed_oid_lens[MAX_ASYNC_SNMP_ITEMS];
+	char	oids_translated[MAX_ASYNC_SNMP_ITEMS][ITEM_SNMP_OID_LEN_MAX];
+	oid		parsed_oids[MAX_ASYNC_SNMP_ITEMS][MAX_OID_LEN];
+
+	int				*errcodes;
+	AGENT_RESULT	*results;
+	const DC_ITEM	*items;
+	int				active_hosts; /* hosts that we have not completed */
+
+};
+
+struct async_snmp_session 
+{
+	struct			snmp_session *sess;		/* SNMP session data */
+	int				current_item;		/* Items index  in the items array we've processing */
+	int				max_items;		//items count int the items array, to stop iterating
+	struct			async_snmp_conf *conf;
+};
+/*
+ * SNMP callback  responce handler
+ */
+int asynch_response(int operation, struct snmp_session *sp, int reqid,
+		    struct snmp_pdu *pdu, void *magic)
+{
+
+	const char	*__function_name = "asynch_response";
+
+	struct async_snmp_session *sess = (struct async_snmp_session *)magic;
+	struct async_snmp_conf *conf=sess->conf;
+
+	struct snmp_pdu *req;
+	zbx_uint64_t	prev_hostid;
+
+	prev_hostid=conf->items[sess->current_item].host.hostid;
+//	zabbix_log(LOG_LEVEL_DEBUG, "In %s() callout hostid %d responce is %u", __function_name,prev_hostid,pdu);
+
+	if (operation != NETSNMP_CALLBACK_OP_RECEIVED_MESSAGE) {
+
+		SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp timeout"));
+		conf->errcodes[sess->current_item]=TIMEOUT_ERROR;
+		async_submit_result(STAT_TIMEOUT, sp, pdu,&conf->results[sess->current_item]);
+
+		conf->active_hosts--;
+		return 1;
+	} else 
+	{
+		async_submit_result(STAT_SUCCESS, sess->sess, pdu, &conf->results[sess->current_item]);
+		conf->errcodes[sess->current_item]=SUCCEED;
+	}
+
+	//iterating to next snmp item in the list while processing the same host
+	//and skipping any non-snmp type items 
+	sess->current_item++;
+	while (sess->current_item < sess->max_items ) {
+		if  (SUCCEED == is_snmp_type(conf->items[sess->current_item].type)) {
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() found snmp item",__function_name);
+			break;
+		}
+		sess->current_item++;
+		zabbix_log(LOG_LEVEL_DEBUG, "In %s() skipping non-snmp item",__function_name);
+	}
+
+	//checking if we're not at the end of items list
+	if ( sess->current_item < sess->max_items) {
+
+		//and still processing the same host
+		if (conf->items[sess->current_item].host.hostid == prev_hostid ) {
+
+			//then sending next oid query in case there is an oid
+			if ( conf->items[sess->current_item].snmp_oid ) {
+
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() Parsing oids and adding null vals", __function_name);
+				conf->parsed_oid_lens[sess->current_item] = MAX_OID_LEN;
+
+				//oid translation
+				if (NULL != conf->items[sess->current_item].snmp_oid )	
+				{
+					zbx_snmp_translate(	conf->oids_translated[sess->current_item], 
+										conf->items[sess->current_item].snmp_oid,
+										sizeof(conf->oids_translated[sess->current_item]));
+				}  else 
+				{
+					SET_MSG_RESULT(	&conf->results[sess->current_item], 
+									zbx_dsprintf(NULL, "zbx_snmp_translate(): cannot parse OID \"%s\".",
+									conf->oids_translated[sess->current_item]));
+					zabbix_log(	LOG_LEVEL_DEBUG, "In %s() cannot translate oid %s for hostid %ld", 
+								__function_name,
+								conf->oids_translated[sess->current_item],
+								conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == snmp_parse_oid(	conf->oids_translated[sess->current_item],
+											conf->parsed_oids[sess->current_item], 
+											&conf->parsed_oid_lens[sess->current_item])) 
+				{
+					SET_MSG_RESULT(	&conf->results[sess->current_item], 
+									zbx_dsprintf(NULL, "snmp_parse_oid(): cannot parse OID \"%s\".",
+												conf->oids_translated[sess->current_item]));
+
+					zabbix_log(	LOG_LEVEL_DEBUG, 
+								"In %s() cannot snmp_parse_oid %s for hostid %ld", 
+								__function_name,
+								conf->oids_translated[sess->current_item],
+								conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == (req = snmp_pdu_create(SNMP_MSG_GET))) 
+				{
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot create pdu for hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item]=CONFIG_ERROR;
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (NULL == snmp_add_null_var(req, conf->parsed_oids[sess->current_item], conf->parsed_oid_lens[sess->current_item]))
+				{
+					SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp_add_null_var(): cannot add null variable."));
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot add  vars  hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					conf->errcodes[sess->current_item] = CONFIG_ERROR;
+					snmp_free_pdu(req);
+					conf->active_hosts--;
+					return 1;
+				}
+
+				if (snmp_send(sp, req)) {
+					return 1;
+				} else {
+					snmp_perror("snmp_send");
+					snmp_free_pdu(req);
+
+					zabbix_log(LOG_LEVEL_DEBUG, "In %s() couldn't send snmp request for  hostid %ld", 
+							__function_name,conf->items[sess->current_item].host.hostid);
+
+					SET_MSG_RESULT(&conf->results[sess->current_item], zbx_strdup(NULL, "snmp_send couldn't send a packet"));
+					conf->errcodes[sess->current_item] = NETWORK_ERROR;
+				}
+			}
+		}
+	}
+
+	conf->active_hosts--;
+	return 1;
+}
+
+
+void	get_values_snmp_async(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num)
+{
+	const char		*__function_name = "get_values_snmp";
+
+	char				error[MAX_STRING_LEN];
+	struct snmp_session	*ss [MAX_ASYNC_SNMP_ITEMS];
+	int					i, err = SUCCEED, max_succeed = 0,ret=0;
+	struct snmp_pdu		*pdus[MAX_ASYNC_SNMP_ITEMS], *response;
+
+	size_t			max_error_len;
+
+	struct		variable_list *var;
+	int			snmp_sessions=0;
+	struct		async_snmp_session *hs;
+	struct		async_snmp_conf *conf;
+
+	zbx_uint64_t	last_hostid=0;
+
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s() Started. Got num:%d OIDs to parse",
+			__function_name, num);
+
+
+	if (NULL == (hs = zbx_malloc(NULL, sizeof(struct async_snmp_session) * MAX_ASYNC_SNMP_ITEMS))) 	return;
+	if (NULL == (conf = zbx_malloc(NULL,sizeof(struct async_snmp_conf)))) return;
+
+	
+	conf->items=items;
+	conf->results=results;
+	conf->errcodes=errcodes;
+	conf->active_hosts=0;
+
+
+	for ( i = 0; i < num; i++) 
+	{
+
+		if (SUCCEED != is_snmp_type( items[i].type )) {
+			zabbix_log(LOG_LEVEL_DEBUG, "skipping non-snmp item %d",i);
+			continue;	
+		}
+		
+
+		if (  
+			0 != (ZBX_FLAG_DISCOVERY_RULE & items[i].flags) ||
+			0 == strncmp(items[i].snmp_oid, "discovery[", 10) || 
+			NULL != strchr(items[i].snmp_oid, '[')
+			)
+		{
+			//skipping any dynamic items, they will be processed slow-old-sync way
+			zabbix_log(LOG_LEVEL_DEBUG, "skipping discovery item %d",i);
+			continue;
+		}
+
+		//setting fail code by default to disable for a while items we haven't been able to access
+		errcodes[i]=TIMEOUT_ERROR;
+
+		if (items[i].host.hostid != last_hostid) 
+		{
+			last_hostid=items[i].host.hostid;
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() found new host host id %ld, session is %d", __function_name,last_hostid,snmp_sessions);
+
+			hs[snmp_sessions].conf=conf;
+			hs[snmp_sessions].current_item=i;
+			hs[snmp_sessions].max_items=num;
+
+			conf->parsed_oid_lens[i] = MAX_OID_LEN;
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() init completed %ld", __function_name,last_hostid);
+
+			//starting new session for it:
+			if (NULL == (ss[snmp_sessions]=zbx_snmp_open_session(&items[i], error, sizeof(error))))
+			{
+				err = CONFIG_ERROR;
+				errcodes[i]=NETWORK_ERROR;
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() Opening snmp sessions: failed to open session for item %d", __function_name,i);
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "Couldn't open snmp session"));
+				
+				continue;
+			} 
+
+#define SNMP_RETRIES	1
+#define SNMP_TIMEOUT	2
+			ss[snmp_sessions]->callback = asynch_response;
+			ss[snmp_sessions]->callback_magic = &hs[snmp_sessions];
+			ss[snmp_sessions]->retries=SNMP_RETRIES;
+			ss[snmp_sessions]->timeout=SNMP_TIMEOUT*1000*1000;
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() session is opened %ld", __function_name,last_hostid);
+
+			if (NULL != items[i].snmp_oid )
+			{
+				zbx_snmp_translate(conf->oids_translated[i], items[i].snmp_oid, sizeof(conf->oids_translated[i]));
+			}  else 
+			{
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot translate empty oid %s for hostid %ld", __function_name, 
+						conf->oids_translated[i],items[i].host.hostid);
+
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_parse_oid(): empty OID"));
+				errcodes[i] = CONFIG_ERROR;
+				continue;
+			}
+
+			//zabbix_log(LOG_LEVEL_DEBUG, "In %s() Opening snmp sessions: created session for item %d, code is %d", __function_name,i,errcodes[i]);
+
+			if (NULL == snmp_parse_oid(conf->oids_translated[i], conf->parsed_oids[i], &conf->parsed_oid_lens[i]))
+			{
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_parse_oid(): cannot parse OID \"%s\".",
+						conf->oids_translated[i]));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot snmp_parse_oid %s for hostid %ld", __function_name,
+					conf->oids_translated[i], items[i].host.hostid);
+				errcodes[i] = CONFIG_ERROR;
+				continue;
+			}
+
+			if (NULL == (pdus[snmp_sessions] = snmp_pdu_create(SNMP_MSG_GET)))
+			{
+				SET_MSG_RESULT(&results[i], zbx_dsprintf(NULL, "snmp_pdu_create(): cannot create PDU object "));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot create pdu for hostid %ld",__function_name,conf->items[i].host.hostid);
+				errcodes[i]=CONFIG_ERROR;
+				continue;
+			}
+
+
+			if (NULL == snmp_add_null_var(pdus[snmp_sessions], conf->parsed_oids[i], conf->parsed_oid_lens[i]))
+			{
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "snmp_add_null_var(): cannot add null variable."));
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() cannot add  vars  hostid %ld",__function_name,conf->items[i].host.hostid);
+				errcodes[i] = CONFIG_ERROR;
+				snmp_free_pdu(pdus[snmp_sessions]);
+				//zbx_snmp_close_session(ss[snmp_sessions]);
+				continue;
+			}
+
+
+			zabbix_log(LOG_LEVEL_DEBUG, "In %s() Sending packet ",__function_name);
+
+			if (snmp_send(ss[snmp_sessions], pdus[snmp_sessions]))
+				conf->active_hosts++;
+			else {
+				snmp_perror("snmp_send");
+
+				snmp_free_pdu(pdus[snmp_sessions]);
+				//zbx_snmp_close_session(ss[snmp_sessions]);
+				zabbix_log(LOG_LEVEL_DEBUG, "In %s() couldn't send snmp request for hostid %ld",__function_name,conf->items[i].host.hostid);
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Couldn't send snmp packet"));
+				errcodes[i] = NETWORK_ERROR;
+				continue;
+			}
+
+			snmp_sessions++;
+		    
+		} else {
+			//the next item belogns to the same host as before.
+			//iterating to the next item
+			zabbix_log(LOG_LEVEL_DEBUG, "%s() Skipping item %d as it belongs to the same host",__function_name,i);
+			continue;
+		}
+
+	} //iteration over the items array
+	int starttime=time(NULL);
+
+
+#define SNMP_MAX_BATCH_TIME (SNMP_RETRIES+1)*SNMP_TIMEOUT
+
+	 while (conf->active_hosts > 0  && (time(NULL)-starttime)< SNMP_MAX_BATCH_TIME) {
+
+		int fds = 0, block = 1, sessions;
+		netsnmp_large_fd_set fdset;
+		struct timeval timeout;
+
+		timeout.tv_sec=SNMP_TIMEOUT;
+		timeout.tv_usec=0;
+
+		//FD_ZERO(&fdset);
+		netsnmp_large_fd_set_init(&fdset, MAX_ASYNC_SNMP_ITEMS);
+
+
+		snmp_select_info2(&fds,&fdset,&timeout,&block);
+
+		fds = netsnmp_large_fd_set_select(fds, &fdset, NULL, NULL, block ? NULL : &timeout);
+
+		if (fds < 0) {
+			zabbix_log(LOG_LEVEL_DEBUG, "End of %s() Something unexpected happened with fds ", __function_name);
+			break;
+		}
+
+		if (fds) {
+//			zbx_alarm_on(SNMP_MAX_BATCH_TIME); //to exit out of use netsnm large fdset glitch if it happens
+			snmp_read2(&fdset);
+//			zbx_alarm_off();
+		}
+		else
+			snmp_timeout();
+		zabbix_log(LOG_LEVEL_DEBUG, "In %s() : waiting for %d pollers to finish", __function_name, conf->active_hosts);
+		netsnmp_large_fd_set_cleanup(&fdset);
+	}
+
+	/* sessions cleanup */
+	for (i = 0; i < snmp_sessions; i++ ) 
+	{
+		zabbix_log(LOG_LEVEL_DEBUG, "End of %s() freeing session for  item %d", __function_name,i);
+		zbx_snmp_close_session(ss[i]);
+	}
+
+	//if something sill left open, it will be closed
+	snmp_close_sessions();
+
+	zbx_free(hs);
+	zbx_free(conf);
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%s", __function_name, zbx_result_string(ret));
+
+	return;
+}
+
+
+
 #endif	/* HAVE_NETSNMP */
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.h glaber/src/zabbix_server/poller/checks_snmp.h
--- zabbix-4.0.1/src/zabbix_server/poller/checks_snmp.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/poller/checks_snmp.h	2019-05-28 11:38:33.383898517 +0500
@@ -32,6 +32,7 @@
 void	zbx_init_snmp(void);
 int	get_value_snmp(const DC_ITEM *item, AGENT_RESULT *result);
 void	get_values_snmp(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
+void	get_values_snmp_async(const DC_ITEM *items, AGENT_RESULT *results, int *errcodes, int num);
 #endif
 
 #endif
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/poller/poller.c glaber/src/zabbix_server/poller/poller.c
--- zabbix-4.0.1/src/zabbix_server/poller/poller.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/poller/poller.c	2019-05-31 11:29:11.284895441 +0500
@@ -496,23 +496,62 @@
  * Author: Alexei Vladishev                                                   *
  *                                                                            *
  * Comments: processes single item at a time except for Java, SNMP items,     *
+ * 				agent
+ * 		    																  *
  *           see DCconfig_get_poller_items()                                  *
  *                                                                            *
  ******************************************************************************/
-static int	get_values(unsigned char poller_type, int *nextcheck)
+static int	get_values(unsigned char poller_type, int *nextcheck,int *processed_num)
 {
 	const char		*__function_name = "get_values";
-	DC_ITEM			items[MAX_POLLER_ITEMS];
-	AGENT_RESULT		results[MAX_POLLER_ITEMS];
-	int			errcodes[MAX_POLLER_ITEMS];
+	//stack is noet enough for 8k items
+	DC_ITEM			*items;//[MAX_POLLER_ITEMS];
+	AGENT_RESULT		*results;//[MAX_POLLER_ITEMS];
+	int			*errcodes;//[MAX_POLLER_ITEMS];
 	zbx_timespec_t		timespec;
 	char			*port = NULL, error[ITEM_ERROR_LEN_MAX];
-	int			i, num, last_available = HOST_AVAILABLE_UNKNOWN;
+	int			i, num_collected=0, num, last_available = HOST_AVAILABLE_UNKNOWN, MAX_ITEMS=1;
 	zbx_vector_ptr_t	add_results;
-
+	
 	zabbix_log(LOG_LEVEL_DEBUG, "In %s()", __function_name);
 
+	switch (poller_type)
+	{
+		case ZBX_POLLER_TYPE_ASYNC_AGENT:
+			MAX_ITEMS=MAX_ASYNC_AGENT_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_ASYNC_SNMP:
+			MAX_ITEMS=MAX_ASYNC_SNMP_ITEMS;
+			break;
+		case ZBX_POLLER_TYPE_UNREACHABLE:
+			MAX_ITEMS=MAX_UNREACH_ITEMS;
+			break;
+		default: 
+			MAX_ITEMS=MAX_POLLER_ITEMS;
+	}
+
+	if (NULL == (items=zbx_malloc(NULL,sizeof(DC_ITEM)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+	if (NULL == (results=zbx_malloc(NULL,sizeof(AGENT_RESULT)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+	if (NULL == (errcodes=zbx_malloc(NULL,sizeof(int)*MAX_ITEMS))) 
+	{
+		zabbix_log(LOG_LEVEL_WARNING,"Cannot allocate memory for polling");
+		return FAIL;
+	};
+ 
+
 	num = DCconfig_get_poller_items(poller_type, items);
+	*processed_num=num;
+
+	zabbix_log(LOG_LEVEL_DEBUG, "In %s(), got %d items", __function_name,num);
+
 
 	if (0 == num)
 	{
@@ -524,7 +563,7 @@
 	for (i = 0; i < num; i++)
 	{
 		init_result(&results[i]);
-		errcodes[i] = SUCCEED;
+		errcodes[i] = NOT_PROCESSED;
 
 		ZBX_STRDUP(items[i].key, items[i].key_orig);
 		if (SUCCEED != substitute_key_macros(&items[i].key, NULL, &items[i], NULL,
@@ -700,41 +739,55 @@
 	}
 
 	zbx_free(port);
-
 	zbx_vector_ptr_create(&add_results);
 
-	/* retrieve item values */
-	if (SUCCEED == is_snmp_type(items[0].type))
-	{
 #ifdef HAVE_NETSNMP
-		/* SNMP checks use their own timeouts */
-		get_values_snmp(items, results, errcodes, num);
-#else
-		for (i = 0; i < num; i++)
-		{
-			if (SUCCEED != errcodes[i])
-				continue;
-
-			SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Support for SNMP checks was not compiled in."));
-			errcodes[i] = CONFIG_ERROR;
-		}
-#endif
-	}
-	else if (ITEM_TYPE_JMX == items[0].type)
-	{
-		zbx_alarm_on(CONFIG_TIMEOUT);
-		get_values_java(ZBX_JAVA_GATEWAY_REQUEST_JMX, items, results, errcodes, num);
+	if (ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type  || ZBX_POLLER_TYPE_UNREACHABLE == poller_type) {
+		zbx_alarm_on(CONFIG_TIMEOUT*2);
+		get_values_snmp_async(items, results, errcodes, num);
 		zbx_alarm_off();
 	}
-	else if (1 == num)
+#endif
+	if (ZBX_POLLER_TYPE_ASYNC_AGENT == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type) 
 	{
-		if (SUCCEED == errcodes[0])
-			errcodes[0] = get_value(&items[0], &results[0], &add_results);
+		zbx_alarm_on(CONFIG_TIMEOUT*2);
+		get_value_agent_async(items, results, errcodes, num);
+		zbx_alarm_off();
 	}
-	else
-		THIS_SHOULD_NEVER_HAPPEN;
 
+	/* by design normal threads where not likely to get */
+	/* more then one item to process, but for future  */
+	/* to allow poller to take several tasks, this 	  */
+	/* part is fixed to be ready for it 		  */
+	for (i = 0; i < num; i++) {
+		/* it maybe that some items are already processed by async methods, skipping them */		
+		if ( NOT_PROCESSED == errcodes[i]) {
+			/* retrieve item values */
+			if (SUCCEED == is_snmp_type(items[i].type))
+			{	
+#ifdef HAVE_NETSNMP
+				/* SNMP checks use their own timeouts */
+				get_values_snmp(items+i, results+i, errcodes+i, 1);
+#else
+				SET_MSG_RESULT(&results[i], zbx_strdup(NULL, "Support for SNMP checks was not compiled in."));
+				errcodes[i] = CONFIG_ERROR;
+#endif
+			}
+			else if (ITEM_TYPE_JMX == items[i].type)
+			{
+				zbx_alarm_on(CONFIG_TIMEOUT);
+				get_values_java(ZBX_JAVA_GATEWAY_REQUEST_JMX, items+i, results+i, errcodes+i, 1);
+				zbx_alarm_off();
+			}
+			else 
+			{	
+				errcodes[i] = get_value(&items[i], &results[i], &add_results);
+			}
+		}	
+	}
+	
 	zbx_timespec(&timespec);
+	
 
 	/* process item values */
 	for (i = 0; i < num; i++)
@@ -753,12 +806,20 @@
 			case NETWORK_ERROR:
 			case GATEWAY_ERROR:
 			case TIMEOUT_ERROR:
-				if (HOST_AVAILABLE_FALSE != last_available)
+				/* for mass problems don't mark host as unreach for async and unreach pollers, because:
+				first, that sometimes causes a "poll" bug in mysql lib (100% thread load on waiting in a poll for mysql, probably solvable by alarm)
+				second, there seems to be no reason for that, async pollers live just fine having even all hosts unreachable */
+				if ( HOST_AVAILABLE_FALSE != last_available && 
+						(ZBX_POLLER_TYPE_NORMAL == poller_type || 
+						 ZBX_POLLER_TYPE_JAVA == poller_type ) )
 				{
 					zbx_deactivate_item_host(&items[i], &timespec, results[i].msg);
 					last_available = HOST_AVAILABLE_FALSE;
 				}
 				break;
+			case NOT_PROCESSED:
+				//this might happen on async processing for snmp
+				//when a host fails answering an item, next ones are not requested
 			case CONFIG_ERROR:
 				/* nothing to do */
 				break;
@@ -772,6 +833,7 @@
 			if (0 == add_results.values_num)
 			{
 				items[i].state = ITEM_STATE_NORMAL;
+				num_collected++;
 				zbx_preprocess_item_value(items[i].itemid, items[i].value_type, items[i].flags,
 						&results[i], &timespec, items[i].state, NULL);
 			}
@@ -789,6 +851,7 @@
 					if (ISSET_MSG(add_result))
 					{
 						items[i].state = ITEM_STATE_NOTSUPPORTED;
+						num_collected++;
 						zbx_preprocess_item_value(items[i].itemid, items[i].value_type,
 								items[i].flags, NULL, &ts_tmp, items[i].state,
 								add_result->msg);
@@ -796,6 +859,7 @@
 					else
 					{
 						items[i].state = ITEM_STATE_NORMAL;
+						num_collected++;
 						zbx_preprocess_item_value(items[i].itemid, items[i].value_type,
 								items[i].flags, add_result, &ts_tmp, items[i].state,
 								NULL);
@@ -813,12 +877,13 @@
 		else if (NOTSUPPORTED == errcodes[i] || AGENT_ERROR == errcodes[i] || CONFIG_ERROR == errcodes[i])
 		{
 			items[i].state = ITEM_STATE_NOTSUPPORTED;
+			num_collected++;
 			zbx_preprocess_item_value(items[i].itemid, items[i].value_type, items[i].flags, NULL, &timespec,
 					items[i].state, results[i].msg);
 		}
 
 		DCpoller_requeue_items(&items[i].itemid, &items[i].state, &timespec.sec, &errcodes[i], 1, poller_type,
-				nextcheck);
+					nextcheck);
 
 		zbx_free(items[i].key);
 
@@ -863,21 +928,28 @@
 				zbx_free(items[i].jmx_endpoint);
 				break;
 		}
-
 		free_result(&results[i]);
 	}
-
+	
 	zbx_preprocessor_flush();
 	zbx_vector_ptr_clear_ext(&add_results, (zbx_mem_free_func_t)free_result_ptr);
 	zbx_vector_ptr_destroy(&add_results);
 
 	DCconfig_clean_items(items, NULL, num);
-exit:
-	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
 
-	return num;
+exit:	
+
+	zbx_free(items);
+	zbx_free(results);
+	zbx_free(errcodes);
+
+
+	zabbix_log(LOG_LEVEL_DEBUG, "End of %s():%d", __function_name, num);
+	return num_collected;
 }
 
+
+
 ZBX_THREAD_ENTRY(poller_thread, args)
 {
 	int		nextcheck, sleeptime = -1, processed = 0, old_processed = 0;
@@ -897,7 +969,7 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "%s #%d started [%s #%d]", get_program_type_string(program_type),
 			server_num, get_process_type_string(process_type), process_num);
 #ifdef HAVE_NETSNMP
-	if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type)
+	if (ZBX_POLLER_TYPE_NORMAL == poller_type || ZBX_POLLER_TYPE_UNREACHABLE == poller_type || ZBX_POLLER_TYPE_ASYNC_SNMP == poller_type )
 		zbx_init_snmp();
 #endif
 
@@ -921,7 +993,7 @@
 					old_total_sec);
 		}
 
-		processed += get_values(poller_type, &nextcheck);
+		processed += get_values(poller_type, &nextcheck,&processed);
 		total_sec += zbx_time() - sec;
 
 		sleeptime = calculate_sleeptime(nextcheck, POLLER_DELAY);
@@ -951,3 +1023,4 @@
 
 #undef STAT_INTERVAL
 }
+
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/preprocessor/preprocessing.h glaber/src/zabbix_server/preprocessor/preprocessing.h
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preprocessing.h	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/preprocessor/preprocessing.h	2019-05-28 11:38:33.383898517 +0500
@@ -25,6 +25,7 @@
 #include "dbcache.h"
 
 #define ZBX_IPC_SERVICE_PREPROCESSING	"preprocessing"
+#define ZBX_IPC_SERVICE_PREPROCESSING_WORKER	"preprocessing_worker"
 
 #define ZBX_IPC_PREPROCESSOR_WORKER	1
 #define ZBX_IPC_PREPROCESSOR_REQUEST	2
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_manager.c glaber/src/zabbix_server/preprocessor/preproc_manager.c
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_manager.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/preprocessor/preproc_manager.c	2019-05-28 11:38:33.383898517 +0500
@@ -40,6 +40,10 @@
 #define ZBX_PREPROC_PRIORITY_NONE	0
 #define ZBX_PREPROC_PRIORITY_FIRST	1
 
+//this must be big enough to hold buffer for occasional slowdownds, so 10-15 threads might submit data without stucking
+#define ZBX_PREPROCESSING_MAX_QUEUE_TRESHOLD 1000000
+
+
 typedef enum
 {
 	REQUEST_STATE_QUEUED		= 0,		/* requires preprocessing */
@@ -1003,7 +1007,8 @@
 
 ZBX_THREAD_ENTRY(preprocessing_manager_thread, args)
 {
-	zbx_ipc_service_t		service;
+	zbx_ipc_service_t	service_requests;
+	zbx_ipc_service_t	service_results;
 	char				*error = NULL;
 	zbx_ipc_client_t		*client;
 	zbx_ipc_message_t		*message;
@@ -1023,7 +1028,14 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "%s #%d started [%s #%d]", get_program_type_string(program_type),
 			server_num, get_process_type_string(process_type), process_num);
 
-	if (FAIL == zbx_ipc_service_start(&service, ZBX_IPC_SERVICE_PREPROCESSING, &error))
+	if (FAIL == zbx_ipc_service_start(&service_requests, ZBX_IPC_SERVICE_PREPROCESSING, &error))
+	{
+		zabbix_log(LOG_LEVEL_CRIT, "cannot start preprocessing service for requests: %s", error);
+		zbx_free(error);
+		exit(EXIT_FAILURE);
+	}
+
+	if (FAIL == zbx_ipc_service_start(&service_results, ZBX_IPC_SERVICE_PREPROCESSING_WORKER, &error))
 	{
 		zabbix_log(LOG_LEVEL_CRIT, "cannot start preprocessing service: %s", error);
 		zbx_free(error);
@@ -1057,7 +1069,22 @@
 		}
 
 		update_selfmon_counter(ZBX_PROCESS_STATE_IDLE);
-		ret = zbx_ipc_service_recv(&service, ZBX_PREPROCESSING_MANAGER_DELAY, &client, &message);
+
+		if (manager.queued_num > ZBX_PREPROCESSING_MAX_QUEUE_TRESHOLD )
+		{
+			ret = zbx_ipc_service_recv(&service_results,0, &client, &message);
+			preprocessor_assign_tasks(&manager);
+			preprocessing_flush_queue(&manager);
+		 } else
+		{
+			ret = zbx_ipc_service_recv(&service_results, 0, &client, &message);
+			if (NULL == message)
+				ret = zbx_ipc_service_recv(&service_requests, 0, &client, &message);
+			/* CPU burn prevention */
+			if (NULL == message)	
+					usleep(1000);			
+		}
+
 		update_selfmon_counter(ZBX_PROCESS_STATE_BUSY);
 		sec = zbx_time();
 		zbx_update_env(sec);
@@ -1100,7 +1127,8 @@
 		}
 	}
 
-	zbx_ipc_service_close(&service);
+	zbx_ipc_service_close(&service_requests);
+	zbx_ipc_service_close(&service_results);
 	preprocessor_destroy_manager(&manager);
 
 	return 0;
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_worker.c glaber/src/zabbix_server/preprocessor/preproc_worker.c
--- zabbix-4.0.1/src/zabbix_server/preprocessor/preproc_worker.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/preprocessor/preproc_worker.c	2019-05-28 11:38:33.383898517 +0500
@@ -123,7 +123,7 @@
 
 	zbx_ipc_message_init(&message);
 
-	if (FAIL == zbx_ipc_socket_open(&socket, ZBX_IPC_SERVICE_PREPROCESSING, 10, &error))
+	if (FAIL == zbx_ipc_socket_open(&socket, ZBX_IPC_SERVICE_PREPROCESSING_WORKER, 10, &error))
 	{
 		zabbix_log(LOG_LEVEL_CRIT, "cannot connect to preprocessing service: %s", error);
 		zbx_free(error);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/server.c glaber/src/zabbix_server/server.c
--- zabbix-4.0.1/src/zabbix_server/server.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/server.c	2019-05-31 11:29:11.284895441 +0500
@@ -158,6 +158,8 @@
 int	CONFIG_PINGER_FORKS		= 1;
 int	CONFIG_POLLER_FORKS		= 5;
 int	CONFIG_UNREACHABLE_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_SNMP_POLLER_FORKS	= 1;
+int	CONFIG_ASYNC_AGENT_POLLER_FORKS	= 1;
 int	CONFIG_HTTPPOLLER_FORKS		= 1;
 int	CONFIG_IPMIPOLLER_FORKS		= 0;
 int	CONFIG_TIMER_FORKS		= 1;
@@ -212,6 +214,11 @@
 char	*CONFIG_TMPDIR			= NULL;
 char	*CONFIG_FPING_LOCATION		= NULL;
 char	*CONFIG_FPING6_LOCATION		= NULL;
+char	*CONFIG_NMAP_LOCATION		= NULL;
+char	*CONFIG_NMAP_PARAMS		= NULL;
+char	*CONFIG_HISTORY_STORAGE_TYPE	= NULL;
+char	*CONFIG_HISTORY_STORAGE_TABLE_NAME = NULL;
+
 char	*CONFIG_DBHOST			= NULL;
 char	*CONFIG_DBNAME			= NULL;
 char	*CONFIG_DBSCHEMA		= NULL;
@@ -276,6 +283,13 @@
 char	*CONFIG_HISTORY_STORAGE_OPTS		= NULL;
 int	CONFIG_HISTORY_STORAGE_PIPELINES	= 0;
 
+//clickhouse specific
+int CONFIG_CLICKHOUSE_SAVE_HOST_AND_METRIC_NAME =0;
+int CONFIG_CLICKHOUSE_SAVE_NS_VALUE = 0;
+int CONFIG_CLICKHOUSE_VALUECACHE_FILL_TIME = 60;
+char *CONFIG_CLICKHOUSE_USERNAME = NULL;
+char *CONFIG_CLICKHOUSE_PASSWORD = NULL;
+
 int	get_process_info_by_thread(int local_server_num, unsigned char *local_process_type, int *local_process_num);
 
 int	get_process_info_by_thread(int local_server_num, unsigned char *local_process_type, int *local_process_num)
@@ -377,6 +391,16 @@
 		*local_process_type = ZBX_PROCESS_TYPE_UNREACHABLE;
 		*local_process_num = local_server_num - server_count + CONFIG_UNREACHABLE_POLLER_FORKS;
 	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_SNMP_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_SNMP;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_SNMP_POLLER_FORKS;
+	}
+	else if (local_server_num <= (server_count += CONFIG_ASYNC_AGENT_POLLER_FORKS))
+	{
+		*local_process_type = ZBX_PROCESS_TYPE_ASYNC_AGENT;
+		*local_process_num = local_server_num - server_count + CONFIG_ASYNC_AGENT_POLLER_FORKS;
+	}
 	else if (local_server_num <= (server_count += CONFIG_TRAPPER_FORKS))
 	{
 		*local_process_type = ZBX_PROCESS_TYPE_TRAPPER;
@@ -445,6 +469,18 @@
 	if (NULL == CONFIG_FPING6_LOCATION)
 		CONFIG_FPING6_LOCATION = zbx_strdup(CONFIG_FPING6_LOCATION, "/usr/sbin/fping6");
 #endif
+	if (NULL == CONFIG_NMAP_LOCATION)
+		CONFIG_NMAP_LOCATION = zbx_strdup(CONFIG_NMAP_LOCATION, "/usr/bin/nmap");
+
+	if (NULL == CONFIG_NMAP_PARAMS)
+		CONFIG_NMAP_PARAMS = zbx_strdup(CONFIG_NMAP_PARAMS, "-n -sn -PE");
+	
+	if (NULL == CONFIG_HISTORY_STORAGE_TYPE)
+		CONFIG_HISTORY_STORAGE_TYPE = zbx_strdup(CONFIG_HISTORY_STORAGE_TYPE, "clickhouse");
+
+	if (NULL == CONFIG_HISTORY_STORAGE_TABLE_NAME)
+		CONFIG_HISTORY_STORAGE_TABLE_NAME = zbx_strdup(CONFIG_HISTORY_STORAGE_TABLE_NAME, "zabbix.history");
+
 	if (NULL == CONFIG_EXTERNALSCRIPTS)
 		CONFIG_EXTERNALSCRIPTS = zbx_strdup(CONFIG_EXTERNALSCRIPTS, DEFAULT_EXTERNAL_SCRIPTS_PATH);
 #ifdef HAVE_LIBCURL
@@ -580,6 +616,10 @@
 			PARM_OPT,	0,			1000},
 		{"StartPollersUnreachable",	&CONFIG_UNREACHABLE_POLLER_FORKS,	TYPE_INT,
 			PARM_OPT,	0,			1000},
+		{"StartPollersAsyncSNMP",	&CONFIG_ASYNC_SNMP_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
+		{"StartPollersAsyncAGENT",	&CONFIG_ASYNC_AGENT_POLLER_FORKS,	TYPE_INT,
+			PARM_OPT,	0,			100},
 		{"StartIPMIPollers",		&CONFIG_IPMIPOLLER_FORKS,		TYPE_INT,
 			PARM_OPT,	0,			1000},
 		{"StartTimers",			&CONFIG_TIMER_FORKS,			TYPE_INT,
@@ -618,6 +658,10 @@
 			PARM_OPT,	0,			0},
 		{"FpingLocation",		&CONFIG_FPING_LOCATION,			TYPE_STRING,
 			PARM_OPT,	0,			0},
+		{"NmapLocation",		&CONFIG_NMAP_LOCATION,			TYPE_STRING,
+			PARM_OPT,	0,			0},
+		{"NmapParams",		&CONFIG_NMAP_PARAMS,			TYPE_STRING,
+			PARM_OPT,	0,			0},
 		{"Fping6Location",		&CONFIG_FPING6_LOCATION,		TYPE_STRING,
 			PARM_OPT,	0,			0},
 		{"Timeout",			&CONFIG_TIMEOUT,			TYPE_INT,
@@ -722,6 +766,21 @@
 			PARM_OPT,	0,			0},
 		{"ExportFileSize",		&CONFIG_EXPORT_FILE_SIZE,		TYPE_UINT64,
 			PARM_OPT,	ZBX_MEBIBYTE,	ZBX_GIBIBYTE},
+		{"HistoryStorageType",		&CONFIG_HISTORY_STORAGE_TYPE,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"HistoryStorageTableName",		&CONFIG_HISTORY_STORAGE_TABLE_NAME,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"ClickhouseSaveNames",		&CONFIG_CLICKHOUSE_SAVE_HOST_AND_METRIC_NAME,		TYPE_INT,
+			PARM_OPT,	0,			1},
+		{"CLickhouseSaveNS",		&CONFIG_CLICKHOUSE_SAVE_NS_VALUE,		TYPE_INT,
+			PARM_OPT,	0,			1},
+		{"ClickhouseUsername",		&CONFIG_CLICKHOUSE_USERNAME,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"ClickhousePassword",		&CONFIG_CLICKHOUSE_PASSWORD,		TYPE_STRING,
+			PARM_OPT,	1,			0},
+		{"ClickhouseCacheFillTime",		&CONFIG_CLICKHOUSE_VALUECACHE_FILL_TIME,		TYPE_STRING,
+			PARM_OPT,	0,			365*3600*24},
+		
 		{NULL}
 	};
 
@@ -766,6 +825,7 @@
 	ZBX_TASK_EX	t = {ZBX_TASK_START};
 	char		ch, *error = NULL;
 	int		opt_c = 0, opt_r = 0;
+	struct rlimit limits;
 
 #if defined(PS_OVERWRITE_ARGV) || defined(PS_PSTAT_ARGV)
 	argv = setproctitle_save_env(argc, argv);
@@ -854,6 +914,27 @@
 		zbx_free(error);
 		exit(EXIT_FAILURE);
 	}
+	//for async version we need lots of sockets 
+	//to be opened. Checking for that limit
+	getrlimit(RLIMIT_NOFILE,&limits);
+
+        if (ZBX_MIN_OPEN_FILES>limits.rlim_cur ) {
+	    zbx_error("WARNING!!! the system has only %ld open files limit, which is too low for ASYNC version",limits.rlim_cur);
+	    zbx_error("Will try to set the limit to %d:",ZBX_DESIRED_OPEN_FILES);
+
+	    limits.rlim_cur=ZBX_DESIRED_OPEN_FILES;
+	    limits.rlim_max=ZBX_DESIRED_OPEN_FILES;
+
+	    setrlimit(RLIMIT_NOFILE,&limits);
+	    getrlimit(RLIMIT_NOFILE,&limits);
+
+	    if (ZBX_MIN_OPEN_FILES>limits.rlim_cur ) {
+		zbx_error("Couldn't set max open files to %d. Please set it manualy via ulimit -n. Exisiting now.",ZBX_DESIRED_OPEN_FILES);
+		exit(EXIT_FAILURE);
+	    } else {
+		zbx_error("Succesifully set max open files to %d. But it's better to set it manualy via ulimit -n. ",ZBX_DESIRED_OPEN_FILES);
+	    }
+	}
 
 	return daemon_start(CONFIG_ALLOW_ROOT, CONFIG_USER, t.flags);
 }
@@ -945,7 +1026,7 @@
 	zabbix_log(LOG_LEVEL_INFORMATION, "VMware monitoring:         " VMWARE_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SMTP authentication:       " SMTP_AUTH_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "Jabber notifications:      " JABBER_FEATURE_STATUS);
-	zabbix_log(LOG_LEVEL_INFORMATION, "Ez Texting notifications:  " LIBCURL_FEATURE_STATUS);
+	zabbix_log(LOG_LEVEL_INFORMATION, "CURL support:		" LIBCURL_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "ODBC:                      " ODBC_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "SSH2 support:              " SSH2_FEATURE_STATUS);
 	zabbix_log(LOG_LEVEL_INFORMATION, "IPv6 support:              " IPV6_FEATURE_STATUS);
@@ -1061,7 +1142,8 @@
 	zbx_vc_enable();
 
 	threads_num = CONFIG_CONFSYNCER_FORKS + CONFIG_POLLER_FORKS
-			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
+			+ CONFIG_UNREACHABLE_POLLER_FORKS + CONFIG_ASYNC_SNMP_POLLER_FORKS 
+			+ CONFIG_ASYNC_AGENT_POLLER_FORKS + CONFIG_TRAPPER_FORKS + CONFIG_PINGER_FORKS
 			+ CONFIG_ALERTER_FORKS + CONFIG_HOUSEKEEPER_FORKS + CONFIG_TIMER_FORKS
 			+ CONFIG_HTTPPOLLER_FORKS + CONFIG_DISCOVERER_FORKS + CONFIG_HISTSYNCER_FORKS
 			+ CONFIG_ESCALATOR_FORKS + CONFIG_IPMIPOLLER_FORKS + CONFIG_JAVAPOLLER_FORKS
@@ -1113,6 +1195,16 @@
 				thread_args.args = &poller_type;
 				threads[i] = zbx_thread_start(poller_thread, &thread_args);
 				break;
+			case ZBX_PROCESS_TYPE_ASYNC_SNMP:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_SNMP;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
+			case ZBX_PROCESS_TYPE_ASYNC_AGENT:
+				poller_type = ZBX_POLLER_TYPE_ASYNC_AGENT;
+				thread_args.args = &poller_type;
+				threads[i] = zbx_thread_start(poller_thread, &thread_args);
+				break;
 			case ZBX_PROCESS_TYPE_TRAPPER:
 				thread_args.args = &listen_sock;
 				threads[i] = zbx_thread_start(trapper_thread, &thread_args);
diff -rNu -x '*.log' -x '*.status' -x Makefile -x '*.o' -x '*.a' -x '*.json' -x '*.Po' -x '*.in.' -x '*.example' -x config.h -x '*.orig' -x '*.rej' -x test.php -x zabbix.conf.php -x '*.ORIG*' -x autom4te.cache -x 'configure*' -x .htaccess -x .git -x '*.h.in*' zabbix-4.0.1/src/zabbix_server/trapper/trapper.c glaber/src/zabbix_server/trapper/trapper.c
--- zabbix-4.0.1/src/zabbix_server/trapper/trapper.c	2018-10-29 22:36:00.000000000 +0500
+++ glaber/src/zabbix_server/trapper/trapper.c	2019-05-28 11:38:33.387898603 +0500
@@ -822,7 +822,6 @@
 
 	zbx_status_counters_free();
 }
-
 /******************************************************************************
  *                                                                            *
  * Function: recv_getstatus                                                   *
Двоичные файлы zabbix-4.0.1/src/zabbix_server/zabbix_server и glaber/src/zabbix_server/zabbix_server различаются
